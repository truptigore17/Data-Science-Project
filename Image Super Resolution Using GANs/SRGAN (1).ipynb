{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from urllib import request\n",
    "import os, sys\n",
    "\n",
    "path_set14 = r\"https://github.com/titu1994/Super-Resolution-using-Generative-Adversarial-Networks/releases/download/v0.1/Set14.zip\"\n",
    "filename=\"Set14.zip\"\n",
    "def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            \n",
    "if not os.path.exists(\"tests/set14\"):\n",
    "    print(\"Downloading Set14 images\")\n",
    "    filehandler, _ = request.urlretrieve(path_set14, reporthook = _progress)\n",
    "    zf = zipfile.ZipFile(filehandler)\n",
    "    print()\n",
    "    print(\"Extracting images\")\n",
    "    uncompress_size = sum((file.file_size for file in zf.infolist()))\n",
    "\n",
    "    extracted_size = 0\n",
    "\n",
    "    for file in zf.infolist():\n",
    "        extracted_size += file.file_size\n",
    "        sys.stdout.write('\\rExtracting %.2f%%' % (float(extracted_size * 100/uncompress_size)))\n",
    "        sys.stdout.flush()\n",
    "        zf.extract(file, \"tests\")\n",
    "print()\n",
    "print(\"Set14 is all set!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Set5 is all set!!\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from urllib import request\n",
    "\n",
    "path_set5 = r\"https://github.com/titu1994/Super-Resolution-using-Generative-Adversarial-Networks/releases/download/v0.1/Set5.zip\"\n",
    "filename=\"Set5\"\n",
    "def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "if not os.path.exists(\"tests/set5\"):\n",
    "    print(\"Downloading Set5 images\")\n",
    "    filehandler, _ = request.urlretrieve(path_set5, reporthook=_progress)\n",
    "    zf = zipfile.ZipFile(filehandler)\n",
    "    print()\n",
    "    print(\"Extracting images\")\n",
    "    uncompress_size = sum((file.file_size for file in zf.infolist()))\n",
    "\n",
    "    extracted_size = 0\n",
    "\n",
    "    for file in zf.infolist():\n",
    "        extracted_size += file.file_size\n",
    "        sys.stdout.write('\\rExtracting %.2f%%' % (float(extracted_size * 100/uncompress_size)))\n",
    "        sys.stdout.flush()\n",
    "        zf.extract(file, \"tests\")\n",
    "    \n",
    "print()\n",
    "print(\"Set5 is all set!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "BSD100 is all set\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from urllib import request\n",
    "\n",
    "path_bsd100 = r\"https://github.com/titu1994/Super-Resolution-using-Generative-Adversarial-Networks/releases/download/v0.1/bsd100.zip\"\n",
    "filename=\"bsd100.zip\"\n",
    "def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "if not os.path.exists(\"tests/set14\"):\n",
    "    print(\"Downloading BSD100 images\")\n",
    "    filehandler, _ = request.urlretrieve(path_bsd100, reporthook=_progress)\n",
    "    zf = zipfile.ZipFile(filehandler)\n",
    "    print()\n",
    "\n",
    "    print(\"Extracting images\")\n",
    "    uncompress_size = sum((file.file_size for file in zf.infolist()))\n",
    "\n",
    "    extracted_size = 0\n",
    "\n",
    "    for file in zf.infolist():\n",
    "        extracted_size += file.file_size\n",
    "        sys.stdout.write('\\rExtracting %.2f%%' % (float(extracted_size * 100/uncompress_size)))\n",
    "        sys.stdout.flush()\n",
    "        zf.extract(file, \"tests\")\n",
    "print()\n",
    "print(\"BSD100 is all set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Coco annotations\n",
      "Downloading train2014 100.00%\n",
      "Extracting annotations\n",
      "Extracting 100.00%"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from urllib import request\n",
    "import os, sys\n",
    "\n",
    "path_coco = r\"http://images.cocodataset.org/zips/train2014.zip\"\n",
    "filename=\"train2014\"\n",
    "def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\rDownloading %s %.2f%%' % (filename,\n",
    "                float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "if not os.path.exists(\"tests\\coco\"):\n",
    "    print(\"Downloading Coco images\")\n",
    "    filehandler, _ = request.urlretrieve(path_coco, reporthook=_progress)\n",
    "    zf = zipfile.ZipFile(filehandler)\n",
    "    uncompress_size = sum((file.file_size for file in zf.infolist()))\n",
    "\n",
    "    extracted_size = 0\n",
    "    print()\n",
    "    print(\"Extracting images\")\n",
    "\n",
    "    for file in zf.infolist():\n",
    "        extracted_size += file.file_size\n",
    "        sys.stdout.write('\\rExtracting %.2f%%' % (float(extracted_size * 100/uncompress_size)))\n",
    "        sys.stdout.flush()\n",
    "        zf.extract(file, \"tests/coco\")\n",
    "\n",
    "    os.rename(\"tests/coco/train2014\", \"tests/coco/images\")\n",
    "\n",
    "    filename=\"annotations\"\n",
    "    path_cocoann = r\"http://images.cocodataset.org/annotations/annotations_trainval2014.zip\"\n",
    "\n",
    "    print(\"Downloading Coco annotations\")\n",
    "    filehandler, _ = request.urlretrieve(path_cocoann, reporthook=_progress)\n",
    "\n",
    "    zf = zipfile.ZipFile(filehandler)\n",
    "    print()\n",
    "    print(\"Extracting annotations\")\n",
    "    uncompress_size = sum((file.file_size for file in zf.infolist()))\n",
    "\n",
    "    extracted_size = 0\n",
    "\n",
    "    for file in zf.infolist():\n",
    "        extracted_size += file.file_size\n",
    "        sys.stdout.write('\\rExtracting %.2f%%' % (float(extracted_size * 100/uncompress_size)))\n",
    "        sys.stdout.flush()\n",
    "        zf.extract(file, \"tests/coco\")\n",
    "print()\n",
    "print(\"Coco is all set!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda\\envs\\stable\\lib\\site-packages\\ipykernel_launcher.py:417: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, add, concatenate, BatchNormalization, LeakyReLU, Flatten, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.utils.data_utils import get_file\n",
    "\n",
    "from keras_ops import fit as bypass_fit, smooth_gan_labels\n",
    "\n",
    "from layers import Normalize, Denormalize, SubPixelUpscaling\n",
    "from loss import AdversarialLossRegularizer, ContentVGGRegularizer, TVRegularizer, psnr, dummy_loss\n",
    "\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import json\n",
    "from imageio import imwrite as imsave\n",
    "from skimage.transform import warp as imresize,resize\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "TF_WEIGHTS_PATH_NO_TOP = r\"https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "if not os.path.exists(\"weights/\"):\n",
    "    os.makedirs(\"weights/\")\n",
    "\n",
    "if not os.path.exists(\"val_images/\"):\n",
    "    os.makedirs(\"val_images/\")\n",
    "\n",
    "if K.image_dim_ordering() == \"th\":\n",
    "    channel_axis = 1\n",
    "else:\n",
    "    channel_axis = -1\n",
    "\n",
    "class VGGNetwork:\n",
    "    '''\n",
    "    Helper class to load VGG and its weights to the FastNet model\n",
    "    '''\n",
    "\n",
    "    def __init__(self, img_width=384, img_height=384, vgg_weight=1.0):\n",
    "        self.img_height = img_height\n",
    "        self.img_width = img_width\n",
    "        self.vgg_weight = vgg_weight\n",
    "\n",
    "        self.vgg_layers = None\n",
    "\n",
    "    def append_vgg_network(self, x_in, true_X_input, pre_train=False):\n",
    "\n",
    "        # Append the initial inputs to the outputs of the SRResNet\n",
    "        x = concatenate([x_in, true_X_input], axis=0)\n",
    "\n",
    "        # Normalize the inputs via custom VGG Normalization layer\n",
    "        x = Normalize(name=\"normalize_vgg\")(x)\n",
    "\n",
    "        # Begin adding the VGG layers\n",
    "        x = Conv2D(64, (3, 3), activation='relu', name='vgg_conv1_1', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "        x = Conv2D(64, (3, 3), activation='relu', name='vgg_conv1_2', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = MaxPooling2D(name='vgg_maxpool1')(x)\n",
    "\n",
    "        x = Conv2D(128, (3, 3), activation='relu', name='vgg_conv2_1', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "        if pre_train:\n",
    "            vgg_regularizer2 = ContentVGGRegularizer(weight=self.vgg_weight)\n",
    "            x = Conv2D(128, (3, 3), activation='relu', name='vgg_conv2_2', padding='same',\n",
    "                              activity_regularizer=vgg_regularizer2, kernel_initializer=\"glorot_uniform\")(x)\n",
    "        else:\n",
    "            x = Conv2D(128, (3, 3), activation='relu', name='vgg_conv2_2', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = MaxPooling2D(name='vgg_maxpool2')(x)\n",
    "\n",
    "        x = Conv2D(256, (3, 3), activation='relu', name='vgg_conv3_1', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = Conv2D(256, (3, 3), activation='relu', name='vgg_conv3_2', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "        x = Conv2D(256, (3, 3), activation='relu', name='vgg_conv3_3', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = MaxPooling2D(name='vgg_maxpool3')(x)\n",
    "\n",
    "        x = Conv2D(512, (3, 3), activation='relu', name='vgg_conv4_1', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = Conv2D(512, (3, 3), activation='relu', name='vgg_conv4_2', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "        x = Conv2D(512, (3, 3), activation='relu', name='vgg_conv4_3', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = MaxPooling2D(name='vgg_maxpool4')(x)\n",
    "\n",
    "        x = Conv2D(512, (3, 3), activation='relu', name='vgg_conv5_1', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = Conv2D(512, (3, 3), activation='relu', name='vgg_conv5_2', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "\n",
    "        if not pre_train:\n",
    "            vgg_regularizer5 = ContentVGGRegularizer(weight=self.vgg_weight)\n",
    "            x = Conv2D(512, (3, 3), activation='relu', name='vgg_conv5_3', padding='same',\n",
    "                          activity_regularizer=vgg_regularizer5, kernel_initializer=\"glorot_uniform\")(x)\n",
    "        else:\n",
    "            x = Conv2D(512, (3, 3), activation='relu', name='vgg_conv5_3', padding='same', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = MaxPooling2D(name='vgg_maxpool5')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def load_vgg_weight(self, model):\n",
    "        # Loading VGG 16 weights\n",
    "        if K.image_dim_ordering() == \"th\":\n",
    "            weights = get_file('vgg16_weights_th_dim_ordering_th_kernels_notop.h5', THEANO_WEIGHTS_PATH_NO_TOP,\n",
    "                                   cache_subdir='models')\n",
    "        else:\n",
    "            weights = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', TF_WEIGHTS_PATH_NO_TOP,\n",
    "                                   cache_subdir='models')\n",
    "        f = h5py.File(weights)\n",
    "\n",
    "        layer_names = [name for name in f.attrs['layer_names']]\n",
    "\n",
    "        if self.vgg_layers is None:\n",
    "            self.vgg_layers = [layer for layer in model.layers\n",
    "                               if 'vgg_' in layer.name]\n",
    "\n",
    "        for i, layer in enumerate(self.vgg_layers):\n",
    "            g = f[layer_names[i]]\n",
    "            weights = [g[name] for name in g.attrs['weight_names']]\n",
    "            layer.set_weights(weights)\n",
    "\n",
    "        # Freeze all VGG layers\n",
    "        for layer in self.vgg_layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "class DiscriminatorNetwork:\n",
    "\n",
    "    def __init__(self, img_width=384, img_height=384, adversarial_loss_weight=1, small_model=False):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.adversarial_loss_weight = adversarial_loss_weight\n",
    "        self.small_model = small_model\n",
    "\n",
    "        self.k = 3\n",
    "        self.mode = 2\n",
    "        self.weights_path = \"weights/Discriminator weights.h5\"\n",
    "\n",
    "        self.gan_layers = None\n",
    "\n",
    "    def append_gan_network(self, true_X_input):\n",
    "\n",
    "        # Normalize the inputs via custom VGG Normalization layer\n",
    "        x = Normalize(type=\"gan\", value=127.5, name=\"gan_normalize\")(true_X_input)\n",
    "\n",
    "        x = Conv2D(64, (self.k, self.k), padding='same', name='gan_conv1_1', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = LeakyReLU(0.3, name=\"gan_lrelu1_1\")(x)\n",
    "\n",
    "        x = Conv2D(64, (self.k, self.k), padding='same', name='gan_conv1_2', strides=(2, 2), kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = LeakyReLU(0.3, name='gan_lrelu1_2')(x)\n",
    "        x = BatchNormalization(axis=channel_axis, name='gan_batchnorm1_1')(x)\n",
    "\n",
    "        filters = [128, 256] if self.small_model else [128, 256, 512]\n",
    "\n",
    "        for i, num_filters in enumerate(filters):\n",
    "            for j in range(2):\n",
    "                strides = (2, 2) if j == 1 else (1, 1)\n",
    "            \n",
    "                x = Conv2D(num_filters, (self.k, self.k), padding='same', strides=strides,\n",
    "                                  name='gan_conv%d_%d' % (i + 2, j + 1), kernel_initializer=\"glorot_uniform\")(x)\n",
    "                x = LeakyReLU(0.3, name='gan_lrelu_%d_%d' % (i + 2, j + 1))(x)\n",
    "                x = BatchNormalization(axis=channel_axis, name='gan_batchnorm%d_%d' % (i + 2, j + 1))(x)\n",
    "\n",
    "        x = Flatten(name='gan_flatten')(x)\n",
    "\n",
    "        output_dim = 128 if self.small_model else 1024\n",
    "\n",
    "        x = Dense(output_dim, name='gan_dense1')(x)\n",
    "        x = LeakyReLU(0.3, name='gan_lrelu5')(x)\n",
    "\n",
    "        gan_regulrizer = AdversarialLossRegularizer(weight=self.adversarial_loss_weight)\n",
    "        x = Dense(2, activation=\"softmax\", activity_regularizer=gan_regulrizer, name='gan_output')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def set_trainable(self, model, value=True):\n",
    "        if self.gan_layers is None:\n",
    "            disc_model = [layer for layer in model.layers\n",
    "                          if 'model' in layer.name][0] # Only disc model is an inner model\n",
    "\n",
    "            self.gan_layers = [layer for layer in disc_model.layers\n",
    "                               if 'gan_' in layer.name]\n",
    "\n",
    "        for layer in self.gan_layers:\n",
    "            layer.trainable = value\n",
    "\n",
    "    def load_gan_weights(self, model):\n",
    "        f = h5py.File(self.weights_path)\n",
    "\n",
    "        layer_names = [name for name in f.attrs['layer_names']]\n",
    "        layer_names = layer_names[1:] # First is an input layer. Not needed.\n",
    "\n",
    "        if self.gan_layers is None:\n",
    "            self.gan_layers = [layer for layer in model.layers\n",
    "                                if 'gan_' in layer.name]\n",
    "\n",
    "        for i, layer in enumerate(self.gan_layers):\n",
    "            g = f[layer_names[i]]\n",
    "            weights = [g[name] for name in g.attrs['weight_names']]\n",
    "            layer.set_weights(weights)\n",
    "\n",
    "        print(\"GAN Model weights loaded.\")\n",
    "        return model\n",
    "\n",
    "    def save_gan_weights(self, model):\n",
    "        print('GAN Weights are being saved.')\n",
    "        model.save_weights(self.weights_path, overwrite=True)\n",
    "        print('GAN Weights saved.')\n",
    "\n",
    "\n",
    "class GenerativeNetwork:\n",
    "\n",
    "    def __init__(self, img_width=96, img_height=96, batch_size=16, num_upscales=2, small_model=False,\n",
    "                 content_weight=1, tv_weight=2e5, gen_channels=64):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.batch_size = batch_size\n",
    "        self.small_model = small_model\n",
    "        self.num_scales = num_upscales\n",
    "\n",
    "        self.content_weight = content_weight\n",
    "        self.tv_weight = tv_weight\n",
    "\n",
    "        self.filters = gen_channels\n",
    "        self.mode = 2\n",
    "        self.init = 'glorot_uniform'\n",
    "\n",
    "        self.sr_res_layers = None\n",
    "        self.sr_weights_path = \"weights/SRGAN.h5\"\n",
    "\n",
    "        self.output_func = None\n",
    "\n",
    "    def create_sr_model(self, ip):\n",
    "\n",
    "        x = Conv2D(self.filters, (5, 5), activation='linear', padding='same', name='sr_res_conv1',\n",
    "                          kernel_initializer=self.init)(ip)\n",
    "        x = BatchNormalization(axis=channel_axis, name='sr_res_bn_1')(x)\n",
    "        x = LeakyReLU(alpha=0.25, name='sr_res_lr1')(x)\n",
    "\n",
    "        x = Conv2D(self.filters, (5, 5), activation='linear', padding='same', name='sr_res_conv2', kernel_initializer=\"glorot_uniform\")(x)\n",
    "        x = BatchNormalization(axis=channel_axis, name='sr_res_bn_2')(x)\n",
    "        x = LeakyReLU(alpha=0.25, name='sr_res_lr2')(x)\n",
    "\n",
    "        num_residual = 5 if self.small_model else 15\n",
    "\n",
    "        for i in range(num_residual):\n",
    "            x = self._residual_block(x, i + 1)\n",
    "\n",
    "        for scale in range(self.num_scales):\n",
    "            x = self._upscale_block(x, scale + 1)\n",
    "    \n",
    "        scale = 2 ** self.num_scales\n",
    "        tv_regularizer = TVRegularizer(img_width=self.img_width * scale, img_height=self.img_height * scale,\n",
    "                                       weight=self.tv_weight) #self.tv_weight)\n",
    "        \n",
    "        x = Conv2D(3, (5, 5), activation='tanh', padding='same', activity_regularizer=tv_regularizer, \n",
    "                   name='sr_res_conv_final', kernel_initializer=self.init)(x)\n",
    "        \n",
    "        x = Denormalize(name='sr_res_conv_denorm')(x)\n",
    "        return x\n",
    "\n",
    "    def _residual_block(self, ip, id):\n",
    "        init = ip\n",
    "\n",
    "        x = Conv2D(self.filters, (3, 3), activation='linear', padding='same', name='sr_res_conv_' + str(id) + '_1',\n",
    "                          kernel_initializer=self.init)(ip)\n",
    "        x = BatchNormalization(axis=channel_axis, name='sr_res_bn_' + str(id) + '_1')(x)\n",
    "        x = LeakyReLU(alpha=0.25, name=\"sr_res_activation_\" + str(id) + \"_1\")(x)\n",
    "\n",
    "        x = Conv2D(self.filters, (3, 3), activation='linear', padding='same', name='sr_res_conv_' + str(id) + '_2',\n",
    "                          kernel_initializer=self.init)(x)\n",
    "        x = BatchNormalization(axis=channel_axis, name='sr_res_bn_' + str(id) + '_2')(x)\n",
    "\n",
    "        m = add([x, init],name=\"sr_res_merge_\" + str(id))\n",
    "\n",
    "        return m\n",
    "\n",
    "    def _upscale_block(self, ip, id):\n",
    "        '''\n",
    "        As per suggestion from http://distill.pub/2016/deconv-checkerboard/, I am swapping out\n",
    "        SubPixelConvolution to simple Nearest Neighbour Upsampling\n",
    "        '''\n",
    "        init = ip\n",
    "        \n",
    "        x = Conv2D(128, (3, 3), activation=\"linear\", padding='same', name='sr_res_upconv1_%d' % id,\n",
    "                          kernel_initializer=self.init)(init)\n",
    "        x = LeakyReLU(alpha=0.25, name='sr_res_up_lr_%d_1_1' % id)(x)\n",
    "        x = UpSampling2D(name='sr_res_upscale_%d' % id)(x)\n",
    "        #x = SubPixelUpscaling(r=2, channels=32)(x)\n",
    "        x = Conv2D(128, (3, 3), activation=\"linear\", padding='same', name='sr_res_filter1_%d' % id,\n",
    "                          kernel_initializer=self.init)(x)\n",
    "        x = LeakyReLU(alpha=0.3, name='sr_res_up_lr_%d_1_2' % id)(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def set_trainable(self, model, value=True):\n",
    "        if self.sr_res_layers is None:\n",
    "            self.sr_res_layers = [layer for layer in model.layers\n",
    "                                    if 'sr_res_' in layer.name]\n",
    "\n",
    "        for layer in self.sr_res_layers:\n",
    "            layer.trainable = value\n",
    "\n",
    "    def get_generator_output(self, input_img, srgan_model):\n",
    "        if self.output_func is None:\n",
    "            gen_output_layer = [layer for layer in srgan_model.layers\n",
    "                                if layer.name == \"sr_res_conv_denorm\"][0]\n",
    "            self.output_func = K.function([srgan_model.layers[0].input],\n",
    "                                          [gen_output_layer.output])\n",
    "\n",
    "        return self.output_func([input_img])\n",
    "\n",
    "\n",
    "class SRGANNetwork:\n",
    "\n",
    "    def __init__(self, img_width=96, img_height=96, batch_size=16, num_scales=2):\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.batch_size = batch_size\n",
    "        self.num_scales = num_scales\n",
    "\n",
    "        self.discriminative_network = None # type: DiscriminatorNetwork\n",
    "        self.generative_network = None # type: GenerativeNetwork\n",
    "        self.vgg_network = None # type: VGGNetwork\n",
    "\n",
    "        self.srgan_model_ = None # type: Model\n",
    "        self.generative_model_ = None # type: Model\n",
    "        self.discriminative_model_ = None #type: Model\n",
    "\n",
    "    def build_srgan_pretrain_model(self, use_small_srgan=False):\n",
    "        large_width = self.img_width * 4\n",
    "        large_height = self.img_height * 4\n",
    "\n",
    "        self.generative_network = GenerativeNetwork(self.img_width, self.img_height, self.batch_size, self.num_scales,\n",
    "                                                    use_small_srgan)\n",
    "        self.vgg_network = VGGNetwork(large_width, large_height)\n",
    "\n",
    "        ip = Input(shape=(self.img_width, self.img_height, 3), name='x_generator')\n",
    "        ip_vgg = Input(shape=(large_width, large_height, 3), name='x_vgg')  # Actual X images\n",
    "\n",
    "        sr_output = self.generative_network.create_sr_model(ip)\n",
    "        self.generative_model_ = Model(ip, sr_output)\n",
    "\n",
    "        vgg_output = self.vgg_network.append_vgg_network(sr_output, ip_vgg, pre_train=True)\n",
    "\n",
    "        self.srgan_model_ = Model(input=[ip, ip_vgg],\n",
    "                                  output=vgg_output)\n",
    "\n",
    "        self.vgg_network.load_vgg_weight(self.srgan_model_)\n",
    "\n",
    "        srgan_optimizer = Adam(lr=1e-4)\n",
    "        generator_optimizer = Adam(lr=1e-4)\n",
    "\n",
    "        self.generative_model_.compile(generator_optimizer, dummy_loss)\n",
    "        self.srgan_model_.compile(srgan_optimizer, dummy_loss)\n",
    "\n",
    "        return self.srgan_model_\n",
    "\n",
    "\n",
    "    def build_discriminator_pretrain_model(self, use_small_srgan=False, use_small_discriminator=False):\n",
    "        large_width = self.img_width * 4\n",
    "        large_height = self.img_height * 4\n",
    "\n",
    "        self.generative_network = GenerativeNetwork(self.img_width, self.img_height, self.batch_size, self.num_scales,\n",
    "                                                    use_small_srgan)\n",
    "        self.discriminative_network = DiscriminatorNetwork(large_width, large_height,\n",
    "                                                           small_model=use_small_discriminator)\n",
    "\n",
    "        ip = Input(shape=(self.img_width, self.img_height, 3), name='x_generator')\n",
    "        ip_gan = Input(shape=(large_width, large_height, 3), name='x_discriminator')  # Actual X images\n",
    "\n",
    "        sr_output = self.generative_network.create_sr_model(ip)\n",
    "        self.generative_model_ = Model(ip, sr_output)\n",
    "        #self.generative_network.set_trainable(self.generative_model_, value=False)\n",
    "\n",
    "        gan_output = self.discriminative_network.append_gan_network(ip_gan)\n",
    "        self.discriminative_model_ = Model(ip_gan, gan_output)\n",
    "\n",
    "        generator_out = self.generative_model_(ip)\n",
    "        gan_output = self.discriminative_model_(generator_out)\n",
    "\n",
    "        self.srgan_model_ = Model(input=ip, output=gan_output)\n",
    "\n",
    "        srgan_optimizer = Adam(lr=1e-4)\n",
    "        generator_optimizer = Adam(lr=1e-4)\n",
    "        discriminator_optimizer = Adam(lr=1e-4)\n",
    "\n",
    "        self.generative_model_.compile(generator_optimizer, loss='mse')\n",
    "        self.discriminative_model_.compile(discriminator_optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "        self.srgan_model_.compile(srgan_optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "\n",
    "\n",
    "        return self.discriminative_model_\n",
    "\n",
    "\n",
    "    def build_srgan_model(self, use_small_srgan=False, use_small_discriminator=False):\n",
    "        large_width = self.img_width * 4\n",
    "        large_height = self.img_height * 4\n",
    "\n",
    "        self.generative_network = GenerativeNetwork(self.img_width, self.img_height, self.batch_size, num_upscales=self.num_scales,\n",
    "                                                    small_model=use_small_srgan)\n",
    "        self.discriminative_network = DiscriminatorNetwork(large_width, large_height,\n",
    "                                                           small_model=use_small_discriminator)\n",
    "        self.vgg_network = VGGNetwork(large_width, large_height)\n",
    "\n",
    "        ip = Input(shape=(self.img_width, self.img_height, 3), name='x_generator')\n",
    "        ip_gan = Input(shape=(large_width, large_height, 3), name='x_discriminator') # Actual X images\n",
    "        ip_vgg = Input(shape=(large_width, large_height, 3), name='x_vgg') # Actual X images\n",
    "        sr_output = self.generative_network.create_sr_model(ip)\n",
    "        self.generative_model_ = Model(ip, sr_output)\n",
    "\n",
    "        gan_output = self.discriminative_network.append_gan_network(ip_gan)\n",
    "        self.discriminative_model_ = Model(ip_gan, gan_output)        \n",
    "        gan_output = self.discriminative_model_(self.generative_model_.output)\n",
    "        vgg_output = self.vgg_network.append_vgg_network(self.generative_model_.output, ip_vgg)\n",
    "\n",
    "        self.srgan_model_ = Model(input=[ip, ip_gan, ip_vgg], output=[gan_output, vgg_output])\n",
    "\n",
    "        self.vgg_network.load_vgg_weight(self.srgan_model_)\n",
    "\n",
    "        srgan_optimizer = Adam(lr=1e-4)\n",
    "        generator_optimizer = Adam(lr=1e-4)\n",
    "        discriminator_optimizer = Adam(lr=1e-4)\n",
    "\n",
    "        self.generative_model_.compile(generator_optimizer, dummy_loss)\n",
    "        self.discriminative_model_.compile(discriminator_optimizer, loss='categorical_crossentropy', metrics=['acc'])\n",
    "        self.srgan_model_.compile(srgan_optimizer, dummy_loss)\n",
    "\n",
    "        return self.srgan_model_\n",
    "\n",
    "\n",
    "    def pre_train_srgan(self, image_dir, num_images=50000, epochs=1, use_small_srgan=False):\n",
    "        self.build_srgan_pretrain_model(use_small_srgan=use_small_srgan)\n",
    "\n",
    "        self._train_model(image_dir, num_images=num_images, epochs=epochs, pre_train_srgan=True,\n",
    "                          load_generative_weights=True)\n",
    "\n",
    "    def pre_train_discriminator(self, image_dir, num_images=50000, epochs=1, batch_size=128,\n",
    "                                use_small_discriminator=False):\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.build_discriminator_pretrain_model(use_small_discriminator)\n",
    "\n",
    "        self._train_model(image_dir, num_images, epochs, pre_train_discriminator=True,\n",
    "                          load_generative_weights=True)\n",
    "\n",
    "    def train_full_model(self, image_dir, num_images=50000, epochs=10, use_small_srgan=False,\n",
    "                         use_small_discriminator=False):\n",
    "\n",
    "        self.build_srgan_model(use_small_srgan, use_small_discriminator)\n",
    "\n",
    "        self._train_model(image_dir, num_images, epochs, load_generative_weights=True, load_discriminator_weights=True)\n",
    "\n",
    "    def _train_model(self, image_dir, num_images=80000, epochs=10, pre_train_srgan=False,\n",
    "                     pre_train_discriminator=False, load_generative_weights=False, load_discriminator_weights=False,\n",
    "                     save_loss=True, disc_train_flip=0.1):\n",
    "\n",
    "        assert self.img_width >= 16, \"Minimum image width must be at least 16\"\n",
    "        assert self.img_height >= 16, \"Minimum image height must be at least 16\"\n",
    "\n",
    "        if load_generative_weights:\n",
    "            try:\n",
    "                self.generative_model_.load_weights(self.generative_network.sr_weights_path)\n",
    "                print(\"Generator weights loaded.\")\n",
    "            except:\n",
    "                print(\"Could not load generator weights.\")\n",
    "\n",
    "        if load_discriminator_weights:\n",
    "            try:\n",
    "                self.discriminative_network.load_gan_weights(self.srgan_model_)\n",
    "                print(\"Discriminator weights loaded.\")\n",
    "            except:\n",
    "                print(\"Could not load discriminator weights.\")\n",
    "\n",
    "        datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "        img_width = self.img_width * 4\n",
    "        img_height = self.img_height * 4\n",
    "\n",
    "        early_stop = False\n",
    "        iteration = 0\n",
    "        prev_improvement = -1\n",
    "\n",
    "        if save_loss:\n",
    "            if pre_train_srgan:\n",
    "                loss_history = {'generator_loss' : [],\n",
    "                                'val_psnr' : [], }\n",
    "            elif pre_train_discriminator:\n",
    "                loss_history = {'discriminator_loss' : [],\n",
    "                                'discriminator_acc' : [], }\n",
    "            else:\n",
    "                loss_history = {'discriminator_loss' : [],\n",
    "                                'discriminator_acc' : [],\n",
    "                                'generator_loss' : [],\n",
    "                                'val_psnr': [], }\n",
    "\n",
    "        y_vgg_dummy = np.zeros((self.batch_size * 2, 3, img_width // 32, img_height // 32)) # 5 Max Pools = 2 ** 5 = 32\n",
    "\n",
    "        print(\"Training SRGAN network\")\n",
    "        for i in range(epochs):\n",
    "            print()\n",
    "            print(\"Epoch : %d\" % (i + 1))\n",
    "            for x in datagen.flow_from_directory(image_dir, class_mode=None, batch_size=self.batch_size,\n",
    "                                                 target_size=(img_width, img_height)):\n",
    "                try:\n",
    "                    t1 = time.time()\n",
    "\n",
    "                    if not pre_train_srgan and not pre_train_discriminator:\n",
    "                        x_vgg = x.copy() * 255 # VGG input [0 - 255 scale]\n",
    "\n",
    "                    # resize images\n",
    "                    x_temp = x.copy()\n",
    "                    x_temp = x_temp.transpose((0, 2, 3, 1))\n",
    "\n",
    "                    x_generator = np.empty((self.batch_size, self.img_width, self.img_height, 3))\n",
    "                    def shift_down(xy):                        \n",
    "                        return xy\n",
    "                    \n",
    "                    for j in range(self.batch_size):\n",
    "                        img = gaussian_filter(x_temp[j], sigma=0.1)\n",
    "                        img = imresize(img, inverse_map=shift_down, output_shape=(self.img_width, self.img_height, 3), order=3)\n",
    "                        #img = resize(img, (self.img_width, self.img_height))\n",
    "                        x_generator[j, :, :, :] = img\n",
    "\n",
    "                    #x_generator = x_generator.transpose((0, 3, 1, 2))\n",
    "\n",
    "                    if iteration % 50 == 0 and iteration != 0 and not pre_train_discriminator:\n",
    "                        print(\"Validation image..\")\n",
    "                        output_image_batch = self.generative_network.get_generator_output(x_generator,\n",
    "                                                                                          self.srgan_model_)\n",
    "                        if type(output_image_batch) == list:\n",
    "                            output_image_batch = output_image_batch[0]\n",
    "\n",
    "                        mean_axis = (0, 2, 3) if K.image_dim_ordering() == 'th' else (0, 1, 2)\n",
    "\n",
    "                        average_psnr = 0.0\n",
    "\n",
    "                        print('gen img mean :', np.mean(output_image_batch / 255., axis=mean_axis))\n",
    "                        print('val img mean :', np.mean(x, axis=mean_axis))\n",
    "\n",
    "                        for x_i in range(self.batch_size):\n",
    "                            average_psnr += psnr(x[x_i], np.clip(output_image_batch[x_i], 0, 255) / 255.)\n",
    "\n",
    "                        average_psnr /= self.batch_size\n",
    "\n",
    "                        if save_loss:\n",
    "                            loss_history['val_psnr'].append(average_psnr)\n",
    "\n",
    "                        iteration += self.batch_size\n",
    "                        t2 = time.time()\n",
    "\n",
    "                        print(\"Time required : %0.2f. Average validation PSNR over %d samples = %0.2f\" %\n",
    "                              (t2 - t1, self.batch_size, average_psnr))\n",
    "\n",
    "                        for x_i in range(self.batch_size):\n",
    "                            real_path = \"val_images/epoch_%d_iteration_%d_num_%d_real_.png\" % (i + 1, iteration, x_i + 1)\n",
    "                            generated_path = \"val_images/epoch_%d_iteration_%d_num_%d_generated.png\" % (i + 1,\n",
    "                                                                                                        iteration,\n",
    "                                                                                                        x_i + 1)\n",
    "\n",
    "                            val_x = x[x_i].copy() * 255.\n",
    "                            val_x = val_x.transpose((1, 2, 0))\n",
    "                            val_x = np.clip(val_x, 0, 255).astype('uint8')\n",
    "\n",
    "                            output_image = output_image_batch[x_i]\n",
    "                            output_image = output_image.transpose((1, 2, 0))\n",
    "                            output_image = np.clip(output_image, 0, 255).astype('uint8')\n",
    "\n",
    "                            imsave(real_path, val_x[:,:,0])\n",
    "                            imsave(generated_path, output_image[:,:,0])\n",
    "\n",
    "                        '''\n",
    "                        Don't train of validation images for now.\n",
    "\n",
    "                        Note that if epochs > 1, there is a chance that\n",
    "                        validation images may be used for training purposes as well.\n",
    "\n",
    "                        In that case, this isn't strictly a validation measure, instead of\n",
    "                        just a check to see what the network has learned.\n",
    "                        '''\n",
    "                        continue\n",
    "\n",
    "                    if pre_train_srgan:\n",
    "                        # Train only generator + vgg network\n",
    "\n",
    "                        # Use custom bypass_fit to bypass the check for same input and output batch size\n",
    "                        hist = bypass_fit(self.srgan_model_, [x_generator, x * 255], y_vgg_dummy,\n",
    "                                                     batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "                        sr_loss = hist.history['loss'][0]\n",
    "\n",
    "                        if save_loss:\n",
    "                            loss_history['generator_loss'].extend(hist.history['loss'])\n",
    "\n",
    "                        if prev_improvement == -1:\n",
    "                            prev_improvement = sr_loss\n",
    "\n",
    "                        improvement = (prev_improvement - sr_loss) / prev_improvement * 100\n",
    "                        prev_improvement = sr_loss\n",
    "\n",
    "                        iteration += self.batch_size\n",
    "                        t2 = time.time()\n",
    "\n",
    "                        print(\"%d / %d | Improvement : %0.2f %% | %0.2f s/steps | \"\n",
    "                              \"GLoss: %0.2f\" % (iteration, num_images, improvement, t2 - t1, sr_loss))\n",
    "                    elif pre_train_discriminator:\n",
    "                        # Train only discriminator\n",
    "                        X_pred = self.generative_model_.predict(x_generator, self.batch_size)\n",
    "\n",
    "                        X = np.concatenate((X_pred, x * 255))\n",
    "\n",
    "                        # Using soft and noisy labels\n",
    "                        if np.random.uniform() > disc_train_flip:\n",
    "                            # give correct classifications\n",
    "                            y_gan = [0] * self.batch_size + [1] * self.batch_size\n",
    "                        else:\n",
    "                            # give wrong classifications (noisy labels)\n",
    "                            y_gan = [1] * self.batch_size + [0] * self.batch_size\n",
    "\n",
    "                        y_gan = np.asarray(y_gan, dtype=np.int).reshape(-1, 1)\n",
    "                        y_gan = to_categorical(y_gan, num_classes=2)\n",
    "                        y_gan = smooth_gan_labels(y_gan)\n",
    "\n",
    "                        hist = self.discriminative_model_.fit(X, y_gan, batch_size=self.batch_size,\n",
    "                                                              epochs=1, verbose=0)\n",
    "\n",
    "                        discriminator_loss = hist.history['loss'][-1]\n",
    "                        discriminator_acc = hist.history['acc'][-1]\n",
    "\n",
    "                        if save_loss:\n",
    "                            loss_history['discriminator_loss'].extend(hist.history['loss'])\n",
    "                            loss_history['discriminator_acc'].extend(hist.history['acc'])\n",
    "\n",
    "                        if prev_improvement == -1:\n",
    "                            prev_improvement = discriminator_loss\n",
    "\n",
    "                        improvement = (prev_improvement - discriminator_loss) / prev_improvement * 100\n",
    "                        prev_improvement = discriminator_loss\n",
    "\n",
    "                        iteration += self.batch_size\n",
    "                        t2 = time.time()\n",
    "\n",
    "                        print(\"%d / %d | Improvement : %0.2f %% | %0.2f s/step | \"\n",
    "                            \"DLoss/Acc : %0.4f / %0.2f\" % (iteration, num_images,\n",
    "                                                            improvement, t2 - t1,\n",
    "                                                            discriminator_loss, discriminator_acc))\n",
    "\n",
    "                    else:\n",
    "                        # Train only discriminator, disable training of srgan\n",
    "                        self.discriminative_network.set_trainable(self.srgan_model_, value=True)\n",
    "                        self.generative_network.set_trainable(self.srgan_model_, value=False)\n",
    "\n",
    "                        # Use custom bypass_fit to bypass the check for same input and output batch size\n",
    "                        # hist = bypass_fit(self.srgan_model_, [x_generator, x * 255, x_vgg],\n",
    "                        #                          [y_gan, y_vgg_dummy],\n",
    "                        #                          batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "                        X_pred = self.generative_model_.predict(x_generator, self.batch_size)\n",
    "\n",
    "                        X = np.concatenate((X_pred, x * 255))\n",
    "\n",
    "                        # Using soft and noisy labels\n",
    "                        if np.random.uniform() > disc_train_flip:\n",
    "                            # give correct classifications\n",
    "                            y_gan = [0] * self.batch_size + [1] * self.batch_size\n",
    "                        else:\n",
    "                            # give wrong classifications (noisy labels)\n",
    "                            y_gan = [1] * self.batch_size + [0] * self.batch_size\n",
    "\n",
    "                        y_gan = np.asarray(y_gan, dtype=np.int).reshape(-1, 1)\n",
    "                        y_gan = to_categorical(y_gan, num_classes=2)\n",
    "                        y_gan = smooth_gan_labels(y_gan)\n",
    "\n",
    "                        hist1 = self.discriminative_model_.fit(X, y_gan, verbose=0, batch_size=self.batch_size,\n",
    "                                                              epochs=1)\n",
    "\n",
    "                        discriminator_loss = hist1.history['loss'][-1]\n",
    "\n",
    "                        # Train only generator, disable training of discriminator\n",
    "                        self.discriminative_network.set_trainable(self.srgan_model_, value=False)\n",
    "                        self.generative_network.set_trainable(self.srgan_model_, value=True)\n",
    "\n",
    "                        # Using soft labels\n",
    "                        y_model = [1] * self.batch_size\n",
    "                        y_model = np.asarray(y_model, dtype=np.int).reshape(-1, 1)\n",
    "                        y_model = to_categorical(y_model, num_classes=2)\n",
    "                        y_model = smooth_gan_labels(y_model)\n",
    "\n",
    "                        # Use custom bypass_fit to bypass the check for same input and output batch size\n",
    "                        hist2 = bypass_fit(self.srgan_model_, [x_generator, x, x_vgg], [y_model, y_vgg_dummy],\n",
    "                                           batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "\n",
    "                        generative_loss = hist2.history['loss'][0]\n",
    "\n",
    "                        if save_loss:\n",
    "                            loss_history['discriminator_loss'].extend(hist1.history['loss'])\n",
    "                            loss_history['discriminator_acc'].extend(hist1.history['acc'])\n",
    "                            loss_history['generator_loss'].extend(hist2.history['loss'])\n",
    "\n",
    "                        if prev_improvement == -1:\n",
    "                            prev_improvement = discriminator_loss\n",
    "\n",
    "                        improvement = (prev_improvement - discriminator_loss) / prev_improvement * 100\n",
    "                        prev_improvement = discriminator_loss\n",
    "\n",
    "                        iteration += self.batch_size\n",
    "                        t2 = time.time()\n",
    "                        print(\"%d / %d | Improvement : %0.2f %% | %0.2f s/step | DLoss : %0.3f | GLoss : %0.3f\" %\n",
    "                              (iteration, num_images, improvement, t2 - t1, discriminator_loss, generative_loss))\n",
    "\n",
    "                    if iteration % 1000 == 0 and iteration != 0:\n",
    "                        print(\"Saving model weights.\")\n",
    "                        # Save predictive (SR network) weights\n",
    "                        self._save_model_weights(pre_train_srgan, pre_train_discriminator)\n",
    "                        self._save_loss_history(loss_history, pre_train_srgan, pre_train_discriminator, save_loss)\n",
    "\n",
    "                    if iteration >= num_images:\n",
    "                        break\n",
    "\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"Keyboard interrupt detected. Stopping early.\")\n",
    "                    early_stop = True\n",
    "                    break\n",
    "\n",
    "            iteration = 0\n",
    "\n",
    "            if early_stop:\n",
    "                break\n",
    "\n",
    "        print(\"Finished training SRGAN network. Saving model weights.\")\n",
    "        # Save predictive (SR network) weights\n",
    "        self._save_model_weights(pre_train_srgan, pre_train_discriminator)\n",
    "        self._save_loss_history(loss_history, pre_train_srgan, pre_train_discriminator, save_loss)\n",
    "\n",
    "    def _save_model_weights(self, pre_train_srgan, pre_train_discriminator):\n",
    "        if not pre_train_discriminator:\n",
    "            self.generative_model_.save_weights(self.generative_network.sr_weights_path, overwrite=True)\n",
    "\n",
    "        if not pre_train_srgan:\n",
    "            # Save GAN (discriminative network) weights\n",
    "            self.discriminative_network.save_gan_weights(self.discriminative_model_)\n",
    "\n",
    "    def _save_loss_history(self, loss_history, pre_train_srgan, pre_train_discriminator, save_loss):\n",
    "        if save_loss:\n",
    "            print(\"Saving loss history\")\n",
    "\n",
    "            if pre_train_srgan:\n",
    "                with open('pretrain losses - srgan.json', 'w') as f:\n",
    "                    json.dump(loss_history, f)\n",
    "            elif pre_train_discriminator:\n",
    "                with open('pretrain losses - discriminator.json', 'w') as f:\n",
    "                    json.dump(loss_history, f)\n",
    "            else:\n",
    "                with open('fulltrain losses.json', 'w') as f:\n",
    "                    json.dump(loss_history, f)\n",
    "\n",
    "            print(\"Saved loss history\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from keras.utils.vis_utils import plot_model\n",
    "\n",
    "    # Path to MS COCO dataset\n",
    "    coco_path = r\"tests/coco\"\n",
    "\n",
    "    '''\n",
    "    Base Network manager for the SRGAN model\n",
    "\n",
    "    Width / Height = 32 to reduce the memory requirement for the discriminator.\n",
    "\n",
    "    Batch size = 1 is slower, but uses the least amount of gpu memory, and also acts as\n",
    "    Instance Normalization (batch norm with 1 input image) which speeds up training slightly.\n",
    "    '''\n",
    "\n",
    "    srgan_network = SRGANNetwork(img_width=32, img_height=32, batch_size=1)\n",
    "    srgan_network.build_srgan_model()\n",
    "    #plot(srgan_network.srgan_model_, 'SRGAN.png', show_shapes=True)\n",
    "\n",
    "    # Pretrain the SRGAN network\n",
    "    #srgan_network.pre_train_srgan(coco_path, num_images=80000, epochs=1)\n",
    "\n",
    "    # Pretrain the discriminator network\n",
    "    #srgan_network.pre_train_discriminator(coco_path, num_images=40000, epochs=1, batch_size=16)\n",
    "\n",
    "    # Fully train the SRGAN with VGG loss and Discriminator loss\n",
    "    #srgan_network.train_full_model(coco_path, num_images=80000, epochs=5)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2840a4860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean gan loss : 104214930352.7259\n",
      "Std gan loss :  53464096423.831406\n",
      "Min gan loss :  5258374656.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2959fe7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean psnr loss : 15.016748608649708\n",
      "Std psnr loss :  2.814803003212561\n",
      "Min psnr loss :  2.1780195832252502\n",
      "Data loaded.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWsAAAD0CAYAAABdAQdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYFNW5P/DvLCxiAMEYQUFHjXNwReOGGpQrruBPoybq1cRrNCZGY1wSERWMmug1PoqKCOIVBRFxQSECssgOw7APywBzYICBmWGGGZh9n+6u3x+9TC9V3VXV1Uv1fD/P4yNTXV11qrr7rVNvnSVNURQQEVFyS090AYiIKDIGayIiG2CwJiKyAQZrIiIbYLAmIrKBzFhsVAjRDcBlAMoAOGOxDyKiFJQBoD+AjVLKVv8XYhKs4Q7Uq2O0bSKiVDcUwBr/BbEK1mUAMGPGDPTr1y9GuyAiSi3l5eW4//77AU8M9RerYO0EgH79+mHAgAEx2gURUcoKSR/zASMRkQ0wWBMR2YCuYC2EuEIIsSJo2X1CiNyYlIqIiAJEzFkLIUYB+B2ARr9lFwF4GEBa7IpGREReemrW+wDc6f1DCHEigDcAPBWrQhERUaCIwVpK+S2AdgAQQmQAmALgaQD1sS0aERF5GX3AeAmAswFMAvAlgHOFEO9aXio/j07fjBvfWRnLXRARJT1D7ayllBsAnAcAQogsAF9KKWOaDlm4szyWmycisgU23SMisgFdNWspZRGAIZGWERFRbLBmTURkAwzWREQ2wGBNRGQDDNZERDbAYE1EZAMM1kRENsBgTURkAwzWREQ2wGBNRGQDDNZERDbAYE1EZAMM1kRENsBgTURkAwzWREQ2wGBNRGQDDNZERDbAYE1EZAMM1kRENsBgTURkAwzWREQ2wGBNRGQDDNZERDbAYE1EZAMM1kRENsBgTURkA5l6VhJCXAHg31LKYUKIiwC8D8AJoBXAA1LKIzEsIxFRpxexZi2EGAXgYwDdPYveA/CElHIYgO8APBez0hEREQB9aZB9AO70+/teKeVWz78zAbRYXioiIgoQMVhLKb8F0O73dxkACCGuAvAXAO/ErHRERATA5ANGIcQ9AD4EMFJKWWltkYiIKJiuB4z+hBC/BfAnAMOklFXWF4mIiIIZqlkLITIAjAfQE8B3QogVQohXYlIyIiLy0VWzllIWARji+bNvzEpDRESq2CmGiMgGDOes46XN4cKeI/WJLgYRUVJI2mD92vxdmJZ70Pd3u9OFLhm8ESCizilpo9/WktqAv3/YUZagkhARJV7SButgipLoEhARJY5tgjURUWdmm2CtgFVrIuq8bBOsiYg6M9sE6zSkJboIREQJY5tgTUTUmSVtsA6uRzNnTUSdWdIGa4ZmIqIOSRusgzFnTUSdmW2CNdMgRNSZJW2wZj2aiKhD0gZrIiLqYJtgzZw1EXVmtgnWzFkTUWdmm2BNRNSZMVgTEdkAgzURkQ0wWBMR2QCDNRGRDTBYExHZAIM1EZENZOpZSQhxBYB/SymHCSF+DmAq3APj5QN4XErpil0RiYgoYs1aCDEKwMcAunsWjQMwRko5FO4hPG6PXfGIiAjQlwbZB+BOv78vAbDS8+8FAK63ulBERBQoYrCWUn4LoN1vUZqU0tv3ux5A71gULI1DgRAR+Zh5wOifn+4JoMaishARkQYzwTpPCDHM8+9bAKy2rjgdFI7bRETko6s1SJC/Afg/IURXALsBzLK2SEREFExXsJZSFgEY4vn3HgDXxrBMAJizJiLyx04xREQ2wGBNRGQDDNZERDZg22Bd29SONgd7uRNR52DbYD341cX48+ebE10MIqK4sE2wVmt3vbSgIv4FISJKANsEayKizsw2wZrtromoM7NNsCYi6sxsE6w5VggRdWa2CdZfbSxOdBGIiBLGNsF6/YGqRBeBiChhbBOsiYg6s6QN1mz8QUTUIWmDNRERdUjaYM3GH0REHZI2WBMRUYekDdbMWRMRdUjaYE1ERB0YrImIbIDBmojIBhisiYhsgMGaiMgGbBWsqxrbMG1tERQOwUdEnUymmTcJIboAmAYgC4ATwCNSygILy6Xqqa+2YtWeSlya1SfWuyIiSipma9YjAGRKKa8C8CqA16wrkraapjYAgMPJmjURdS5mg/UeAJlCiHQAvQC0W1ckIiIKZioNAqAB7hRIAYCfArjVqgIREVEoszXrpwEsklJmAxgMYJoQort1xQLSwsyQyyQIEXU2ZmvW1ehIfVQB6AIgw5ISebDFBxFRB7PB+h0AnwghVgPoCuAFKWWjdcUiIiJ/poK1lLIBwN0WlyWAWhqEI/ERUWdlq04xRESdVdIGa+asiYg6JG2wDoeBnIg6m6QN1uGa7hERdTZJG6yJiKgDgzURkQ0wWBMR2YC9grUnj83Hi0TU2dgrWBMRdVK2DNaRWu5tL6mBw+mKT2GIiOIgaYN1+IZ72tF65+Fa3DYhB+N+3GN1kYiIEiZpg7XZvHRFfSsAYOfhOusKQ0SUYEkbrImIqIPtg3V+aW2ii0BEFHNJG6zD5az9HzDe+v6amJeFiCjRkjZYq+WstQL4rz7IQVVjWyyLQ0SUUEkbrMMJDuRbi2swJ680IWUhIoqHpA3WHHOPiKhD0gbrcDicNRF1NrYM1moYv4kolaVMsCYiSmW2DNZq03oxx01EqcyWwToethXXoKXdmehiEBEBYLBWVVLdhNs/yMFL/8lPdFGIiADYNFjH+mFiXbMDALC9hF3ZiSg5ZJp9oxDieQC3AegKYKKUcoplpSIiogCmatZCiGEArgJwNYBrAQy0sEyaPLN6sZ01EXU6ZmvWNwHYAWA2gF4AnrWsREREFMJszvqnAC4F8BsAjwKYIYSwtPVcmtmtsdZNRCnIbM36GIACKWUbACmEaAFwEoAKqwoWLtWhMCITUSdjtma9BsDNQog0IcQpAI6HO4AnHnvHEFEKMlWzllLOE0JcA2AD3AH/cSll/HqQaFSs/zozD2W1zXErBhFRvJhuuielHGVlQYKp5awjVZq/33Y4JmUhIko0W3aKqW1uN7T+5oPV+M9W7ckJvt5YjFV7KqMtFhFRzJiuWSdCXYu7Z+ETM/MMve+uSWsBALdfdKrq66O+3Q4AKHpjZBSlIyKKHVvVrKs98yw6XGwNQkSdi61q1q0Ol6H1FUXB/qONMSoNEVH82KpmbbRV3ker9mP42yt9f/+wowzTc4sivo/tuIko2diqZm3U5oPVAX8/NmMLAOB3V2YloDRERObZqmbtsnAEp199kINxi6Vl2yMiiiVbBWsrkxNbi2swflmhhVskIoodewVrppKJqJNK2mCdpvI40UgaJKfwqJXFISJKqKQN1motMoxUrGPRFru2qR0fr96vOrs6EVEs2ao1SKKD5Auzd2D+jjKcf2pvDDnzxISWhYg6l6StWecdqglZlshY3dDqwErP+CHtTmOdc4iIopW0wVotjWG06Z7p2WZUPDZjCxpaHdZtkIjIgKQN1mqMVqytrIlzVD4iSiR7BeuwU33FTmkNJzQgosRK2mB9eVbfqLehJw0y+JXFEddpNziAFBGR1ZI2WGf3+0lc9qNnIgMrc99ERGYkbbBOT0CEfHuxREt7/KaSJCLSyzbBekCf48Ku/895u6Le5/vLCjF1bVHIcrXelERE8ZS0wTq4Yn1a3x6Gt2GmNUibSn7aLmmQNocLX244BBdn0iFKOUnbgzG4Zm1meNTOFrImLC/E+KV7cVzXDM35JonInpK2Zp2RHhSsTTTIsKqdtV1q1scaWgF0TCxMRKkjaYN1cHx0KQp+N+R0AMD5p/bSuZXoo3Wrw4mCsvqotxMLzW1ObC8J7ZZPRKknaYN1MJei4Kc/6QYAyC+t0/UeK2rWL3+/E3/4bFP0G/LzWW4R8ktro97Os7O24bYJOTjqqVETUeqKKlgLIX4mhCgWQgyyqkBeXTMDi2bmmZkVWZAtB8PXXJvaHJi3/bChbb70n5249f010RQLgHu2G8Bdwyai1GY6WAshugCYDCAmfbFDctZmHjDGYZi+sXN24i9f5CFr9Py4tdE+UteCrNHzUVLNbvBEnUU0Neu3AHwIwFi10qTtJbWqExIk2mG/cUM2HKhCZX1gSqLVYX0A312mLw1ERKnDVLAWQjwIoFJKucja4rhV1reiXqVFQ4PBVg7xCO3+LUUe+GQDLnttie9vWV4PMWYhfthRZmibi3aWhw3yiejdSUSJZbZm/RCAG4QQKwBcBOAzIUQ/qwp12WtLMGXNgZDlrRYNqNSoc1zqgvL6iLX5cHFzh+ch4pLdR3SXbcOBKvxp+mb87w8FIcvrWtzjmDBYE3U+poK1lPIaKeW1UsphALYCeEBKWW5FgcI1RXMYbGytlbL+29fbdG9D7QIxeeV+Q+XwyjtUDUeEWWZqmtoAICAfXd/Sjrsn5+LPn28GAKRbEKvHzsnH0qCLSCxSNkRkjaRrujdrc4nmaw6nscSG1toF5dHlfNf4zZyud9yQ/NJa3DFxLd5avMe37OZ3V6GsNvJDQm8X+N2e9t5pJmrWtU3tAV3pp687iIendTRJ3F1WBzFmIRbmG0vZEFF8RB2spZTDpJQFkdfUJ1wYMjpjuVZrECNbidSgRCtutjqc+Ps3HTX4Sk9baP+HgwXl9fhi/SEDpXELbinj5S3q2Dn5uP/jdQGvDX51sa9mrsZ7R7OsoALlte7WJgvzLblZIiILJF3NOlytsc2iiWqNNAOMNN61WnkVRcFK6TcNmMVPOvWkQXIKj4UsW1pQoWv7u8rcufZvNhUbKlcwWV6Peybnsh04kQWSLliHe3hmdMYWrZgcLlYH7z1isFZZ9tXGYvxxunotNpq47b1TCL5AvPPjHmSNnh+XduVqZSqualJ97Z/zdmH9gSpsOlgV51IRpZ4kDNbarxmtWTs10iZWzuWodm3JOxT6kDSaZ4LBwTl4n9/llQIwntO3wlcbizH0zeXYWFRl2Tglc7cdxsvf70RLuxObD1YDcF8UPl93ELVNkWf2SRSnS8H6/cdClm05VB2X/SuKgu+3HeaD4hSVfME6TLRuNxistdIdVtZA1Uob6847WncfelL6G4uqNGvCZmzyBNM/f74Ft03Iwa7D0XfYeWJmHqauLcILs3fgrklrUVLdhG0ltRgzJx/PfbsdAPDhyn24c2KO7z0ul5LwWX4mrSjEPR+tw9p9HQ+gJy4vxJ0T12JjUcfdRW1zO7JGz8fXUaaZgq3bX4W/zswLafYZSUOrA/srGywti1FLdx+J+sF/qku6YB2uoYNaHjYcrZhs5dj8elpmHKxqMhy+m9oc+MsXW0J6RALadx96cvG/+TAXQ99cHnYdM9cy72BSFfUtYddranOgsEJfYNjpGbCrodXhC8RVje6mjW8sKMAWvzuYtxZLDBq7EE1tiRsedq/nuI7UdZyDgiPuFjxltR3LSj3NMj9R6UsQDe+d5z6DgfeBKetx3dsrLS2LUQ9P24Sb312d0DIA7otGjl9rLz2yRs/Hvxda1sZCU9IFays7fGgFLzPjjBgR3Jxv88FqX+9LvUe3dt8xzNtehneXdDT1q25qR0u7U/McaaV9rPDM11sx2lOrjcafpm/G9eNWqpbV5VLw4uwd4TegcQK/8TT5NNrLNdjRhtaIbeE3FVUZHrzLjOKqJkM13h5dMwAATQYf6G4JStt5WwOFO8b80lrsKIl+5Eg1X208BDFmQcTPIRYenrYJ93+83vD7Jq3YF4PSBEq6YP39Vut+BPmH1b9M4UKa0UuF3jSIt8YXbTh9a5HUfM1p4iK0U+Mc+ZuacwDfbSnFlxsj37ZHutPw1lrUUlGlNc2YodKU8bb3c7B2n7G7Kq8Gnb1VAaCl3YlL/7UEY+bkh13v1x/m4i9f5Gm+rtb2Xu/3yv+uY+ibyw3VeL13XOHSfDM3HMJ1b60Iu53dnnTElxuKsVyqtyC69f01+H8TQkeOXLLrCH7+wg+6ewmreXXuLrQ6XGiJoseyw+ny9SuobW7HeS8txLr95r5D4cTzoX7SBevSmsBOIvJfN5veVku7+oetllrwMv6AUd/P0PuZRvpwtZoCelV5ejiqCZ57UZZHnjRh5PjIQ7W+PDdwMmJFUVBRp57u0PvlNXKe25wujF+618A73GZtLsH5/1iEvUfqsa24BvUt6g8nXS4Fc/JKfTXS+Z6xXIqrmkIeDpp9eKfneBftLMf141Zi/vboOiaF29fz3+3A/qONurazpvAofv/pRqzQCNhe149biQ9XumuW437cA4dLwQGd+4iVW95bjewxCwC4+xA0tjkxYVmhZdvPO1SNh6duRHscH+onXbAO1i0zI+77NHKxVIvVajUr7yaDt60n1Pu/ZYWs1Cxf8OBXB481evZp7Rfq05wiXP76UhRWNJhu5WK6SAbet6zA3Z1+R2ktbv8gB3/8zN2ccs3eoxj3Y0d6aXZeKZ76ais+Xu0eRqCh1YGs0fMx9M3luHPiWt967tvzhRH3W9PU5rtwGjk/3our+QdtsRkz5miDdgUBcN8NvLEg9jlbI/bqfC5i1pNfbsXSggoUV1v3sD6SpJ0w1y70pkG8Odrg1yLFnu0ltQGBraqxTbO1SU2z+o/KbGBcWlCB3KD0w/aSGqze6+7wc6jKfO3JqhYzL3+/U3WERn/enq95xe5a8m+nuHOSl5zeB9dmn+R7aOm949I6X/N01nhfnrsLDa0O/OW6s3Wtr8evJ61Fty7peOK6szHkzBN9y8trW1Ba04xLTu8T9v2vzt2F2XnaQzkA7kksjusaWjn6+zfbcHKvbrgsqy+6ZaYH3P3dMznX4JHEV3Vj+AtNtOLZtSHpa9bJTu/zUG/t1uiHu6M0dBxvrW1oPViK5vs0ZU3goFW3TcjBcv/emQZ5MzXXvbUSj8/YYnwDQed76toifLulIwi9tVjima+3BqQ8Rs1yPxhtaXdhya6Owas2FenrrBPpzmTcYhnwIBgAFu8KHCRLrUmjVjpC7eHrpoPVyCk8hns/WofiqiZf65jhb6/AXZPWBqzrLe6Dn27AOWMX4uXvd+KTnAOo9mujrvZw8MkvtfPwv5uyAYPGLsSfgjp7rT8QeA71fNeKjjZi9LfbIz5AnO3pP6BlxvqD+DTH3aJmd1kdhry+1Hfh9br4nz9GFVCrGtt8bf3VdOqcdaIZf8CoM2ft/b+JNEjwL0Dr67G/Uv3HH+kL9fgXWzS/0LtjNFlwaU0z5u8ow1kv/GDpdr/eVILvtpTikzVFqq/7z6f5/rJCvDJ3Z8Rtap2bXYfr0OpwYvyyQry7JHxO3ZvT9dfmcKnmpycGtSwIbj8+9M3lvmnhGsO0/FghK9Hc7sTUtUUhr90XNHYMAGzQcfEKvghpGTVru2Yzzie/2oovNxb7hhDWMnZOPp6Ymac5uNuLs/PxytxdqKxvxR+mbUJ5XYvvwqwm0v7U3D05F3dNWhvyPMjLf2mk3s7RskWw/ubRK+O6v2hz1mrv1+xNqac8+otj6v3zt5f5arzBF5/gB75WM9zcUOfqMzfoGyDr05wizfSRl1ZTzxHjV+PZb/Q3Z5y7LbSlk55yqgX6cG3VtxbX4OsILXfqWxzYVhzYZC/aSuKM9Qd9355dZXW4/LWlhrcR/H2Yu+2wb0A0h9OFrNHzkTV6Pj5a1XFObp+wxvc9VRs73tuZzj+YNrQ6IvYJADrO8zCNFjT+5+zhqRsjbi8atgjWFw7oHbd9WXFToxZ/tHLWegT/iIzeeulZ3Uyzv2RWrtFaRc0Hy90/fK0zEO56EqmlhL8nZoamGdZodMDwTxFEqrWrlWOUjjbxt3+QE/B3bXM7NhwwP47Li7PVmzy2O11YtacSDqfL3Ru1uGOEx2B1GrXTrNHz8eSXW31/v+7XS/NwbfjPWm30yBvHrcTlry3V3Sv6kEavX/8L+U4Leu+Gk3TB+g+/PMP37y4Z7ut0l/T4FtNIQFWvWYd5wGiqNYixh5KR3q/GbAeE4ONXwrxmlDwSXQomv9TYj0erBq0WVLzqIjzcVGuKqee86L0z8HrwU2tqdXdPzrW8TcnZLy7AA59swG8m5+KeyR3pF7XhgcPNBjXf4PR4WtqdLl+A/zTnAEbN2oaHVGrF3tZB4fh/ZZrbnVi//1jAuPFWSrpgfcoJxwEAHrwqC3tfGwHAPV7IT7olZ8OVcM30/DlNPmBUe4/ebXgDha6adRQ1fy0xqawbiCRatSFNGuV9NMw44BE3qeMkvLmwIGS9SBcBwP2gLmhvRoqmycqPzT/1kHeoJiCtdkylpUasexdX1LUE9FA8cLQRX28qCbkgL95Zjn/N3x1YNpVbrODfyz0frUP2mAUxGacm6SKg1keV/8pNqG9px/7KxpDbNyulwYqctUrN2hlFGkTHEtX3GTiQWHZVjwcrfuPhAsXrP+zWfM2o4N1MXLEPJ/6kW9A6kQ/o1x+qtwKJNSO9Ewe/stjQtmP9Pbz89eA8uvrVX22I47nbD+P2i04NWBauZVb3Ltb2EUm6mvXJvdxf2lM9NWx/Pbt38dW8T+ndHQDw2LCz8P5/X2zZ/vV+V7wj16nd5qpt4yvPCGtmflDBKQqj29CzvtFZeLz0toaxjGYxo/+Rh9vCR6v2G6+pQ38P13/O2xXQNV7PZxbcWcWqMBepxOGmoov6YbgFB1ETppdvMG+fAT0aW0Nry/F81JN0NeuRF/RHtwcycN2gn6m+flLPbvjgvl/gyrNORGOrA6eccBwWWDhv4DtL9qBRx8htd0zMwaYxN2h0ignlnQA3+LXxywrxzI0i7L6Cu7TGImftX6Mx8gVMlrSJFRWySPuPOMWbxr9D1tN40b+NsJkHvlrNy4xK5D2WFQ+6gyfEDrdF/4mpI1khK3DfFacFLIt12sZf0tWs09LScMO5J2vOMwgAIy/sj77Hd8XAvj2QkZ6Gm8/rZ2kZ9IzN4K3V6E2DhHst0v6CZ3WPRc46ESOcBYvmi29F54RI+49USVY0/m2uLMbfE6+wYWSmJaOsCH7e+U6tptbGPJ4XtqQL1mZkZlh7GMHBMRzVmnWYTzB4OErA3SmlJMwYA8EzwOjN6/l6TepY17I0iN9mjLYG0VUCzbG8je3LzP7NBCIj7/Ff18zFx6pKXpwTWwESMTWdEd75RL3f7XgOw5wSwRoA3rzrwoC//0ucZHpbR+r0XZk/X3dQdfmincZnBQ83EE5wW1CjXwQ9PwAzD3asyld3dMXXUQaNVSz5cVj4+/KeGbObNHM8VqWkEpoGicENnpVx0zuZtJdW6smqlJS/pMtZm3X3ZQNx92UDfWNCKAAufNnYk2ijxszJx+0XnRKy3EwtNdwXKnh7en/IvjSIjnVNlVlty37xW++PxOlSkJmRFlXtONatQQDrat56ymrqXMQpyobbTfTpn+SuWQcPu6xVyYlFJ7OUqVl79ezeBT27d0Gv7l001+nTI/C1R689K+J2R98ySHW5VZPU1mmMtQyE1qz11oK9bT0VHbUVs02mQlIdJjbTsevE5qwjbSLSOVJ71cgcnf4/cHM1a2skMg2S7E1IgwdL0wrKsTiMlAvW/u65dKDq8tznhwf83b1L5NOgFdDNpDzUrN57FHdNWotH/AYa8gpuMqT3h/zEzDy8t2Svrttjo/POeVlZo42qZh19MSKeJ8taW2ilcky2yPG9P0610ljuxpJsVtA2rGyxVB7UbFHr8VYs0iCmgrUQoosQYroQYrUQYoMQ4jarC2aF1+44HxtedAfm/p522QDQNeiB5DXZ4fPbA/q423Z/+NtLQl4z+2BOjdZQjMEBfHqueq5czTtL9gQMtK/FO1j715tKdI2+BgArZSVKagIfjKpN1qo1Y4/XsoIKuFxKVD9UK2pkkTYRaQyKaPmPCmfmxx6vDEIsa7/JngaZtSVw2FY9Y4ZYxWzN+rcAjkkphwK4BcAE64pkncyMdPysZ3cUvTEScx6/GoC7nXZ6ehpWPftfAIAzfno8fnGa9sDtz98yCEueuRYAcPP5/VD0xsi4jwIYTG086at/fqLKmm6fGQjugLsDiB7Tcg+GzDj/r/m78ebCArQ5XL6LzyOfbcJDUzfi+nHq8wk+NmMLXvo+H4t13qUUq/xAwo0poVe0v69oc9b7/Ia41TsUacB2Db/DnBHjtWch15ruTcv2kpqAFNaC/HK0R3kxCBkK1cITs624BscaWn1B+gWNCZ5jcUFLM5PrE0L8BECalLJeCHEigI1SyjP9Xs8CcGDp0qUYMGCAZYWNRl1LOy58eTHuuPhUvHPPRQDcbYvT0tKQkZ6GbcU16Ht8V8jyemwsqsLTN2QjMz1Ns1lg9osL0Kby6Pri005AGgKb6M18ZAiW7j6Cj9ccwEu3nosbzj0Z3TLTUVHfivFL96KwokH3vHha9r8+AmdaPDY0We+a7JPQs3tm1PMsppJxdw/GM0EdWezuh78Oxbmn9DL8vpKSEgwfPhwAzpBSFvm/ZqpmLaVs8ATqngBmARhjZjvx1Kt7Fyz927V4464LfMsyM9J9nW8GDzwBA/v2wPXnnoznR5yD7l0ywrbfLvjnzRgcNHTriyPOwaxHr8J3j12NH5++Bj26ZuCp68/GkDP74sWR52DWo1fi91dnYWDfHvhZr+44/9Te+OiBS7Hs78M09+O9Awj2/C2D8Oav3c0V+/fujvT0NGwZewNyRl+HZX+7Fu/de1HIe+6+dAA+/f1lAct2vnITVj6rvf/9r4/A1KD3/P3GbM319frsocux8tlhOM/EFzre3v7NYJzx0+Mt2daqPZUhgbpbZjpGXtDfku3bUSID9X9ffprq8keGnhGybPrDl+ve7sC+ocNlRMtUzRoAhBADAcwGMFFK+UnQa1lIspp1rDicLtS3ONDn+K5Rbcc768gKWYknh5/ta2WRlpYGl0vBx2v2417PF0txAb17aLd28Vq0sxx9enTFJaf3wbaSGpzTrxeO65qBj1fvx3mn9MaVZ3WkTkqqm3DoWBO2l9b62nyve344+vnl+htbHWh3unBCj64orGjQTGsEm3j/L/CY3xRewwf9DFMe7LgA/Gn6JizaGXjbP/KC/hh767k4oUcX3DM5F9tUpqG66byTMe7ui7BcVuDbzSXodVwXvHrc+4rbAAAG3ElEQVTb+b5zkzV6PgDgrJOOR0u7C6U1zbj09D7Y5PdsYMr/XIqHpwU+ExjQ5zhfN+T7rzgNr93hvsCPmbMDn69zD+t50cAT8MdrzsSIC/rj3o9ysW5/R54/Mz0t5FnGfVechtqm9pBhPh8ZegZeHHkuAPdD3nE/7sELIwbhrkkdcxtentU34DmCOLkn5v31lzjW0IYh/xs6wH/WiT2w6Olr8Idpm7B6r7kHx1qevj4b7/hNYXbnxafiwauzcMGpvbG3ogE3vrPK99pjw87CqJsHoaXdifS0NHTNTEfuvmP4aNU+bC2uwYInrwkof8/umQHzaV511ono06Or75yNvmVQxIl5N425HodrmnHbhNDB3k48vis2j70BbQ4X7p6ciz49umDK/1wGp6Lg7BcXBKxb9MZI3/fHq/C1WzBhufasQLde2B/j770Y6WF6X0cSrmYNRVEM/5ednX1ydnb27uzs7OEar2dlZ2crxcXFCtnPoWONytZD1Ybe0+5wKqXVTYrD6VLeW7JHqWpoVXIKK5WpOQd86+wuq1Uq61tC3ut0upSDRxuVbcXVypHaZtXtu1wuxeVyKYqiKMsLjiinPzdPmbutNGyZmlodyuaDVSHLa5ralHaHUymualQURVEcTpdS1+xedrS+RXG5XEpzm0Npdzh9+9SjqqFV2XW4VlEURdl7pE6ZnlukLNt9xLcfRVGU5jaH8sfPNirLC44ohRX1mttyuVzKpBWFyuGaJsXlcinbisN/Hi6XSzn9uXnK6c/NUxpb233L91c2KHXNbcqavZWK0+lSnE6XsmpPhe+4Plq5Tzn9uXnKOz9KRVEUpbG1XXlvyR7lxnErlYKyOmVTUVXIdyHcOWlucyhFRxuUH7YfDlte/209OXOLcvpz85TmNoeiKIqyp7zO9+9gDs8x+Kuoa1FW76kMWe50unzfm5rGtrDlqG5sVa57a7ly9gs/KDtKasKu++WGg8qZz89XXpqzQ5m5/qAyX+ex6lFcXKxkZ2cr2dnZWUpQXDWbs34PwD0A/C9zt0gpmz2vZ6GT1KwpMWqb29H7uMh3F5T8XC4FDpeCrpkp3ZJYl3A1a1M9GKWUTwJ4MvqiEZnDQJ060tPT0DWK1EFnwUsZEZENMFgTEdkAgzURkQ0wWBMR2QCDNRGRDTBYExHZQKwmH8gAgPJya4YPJSLqDPxiZkbwa7EK1v0B4P7774/R5omIUlp/APv8F8QqWG8EMBRAGQBnhHWJiMgtA+5AvTH4BdMDORERUfzwASMRkQ0k1ezmQoh0ABMBDAbQCuAPUsrCxJbKOkKIPADesT4PAJgM4D0ADgCLpZSvpMo5EEJcAeDfUsphQoifA5gK95wd+QAel1K6hBD/ADAS7uN/Skq5QWvdRByDUUHH/AsAcwF4x9OcJKX8KlWOWQjRBcAnALIAdAPwLwC7kMKfs8YxlyBOn3Oy1ax/BaC7lPJKAKMBvJ3g8lhGCNEdAKSUwzz//R7AhwDuA/BLAFd4fuC2PwdCiFEAPgbgHQx7HIAxnmng0gDc7jnWawFcAeBeAB9orRvPspulcsy/ADDO7/P+KsWOWW1qv1T/nNWOOW6fc1LVrOEOWgsBQEq5TghxaYLLY6XBAHoIIRbDfd5fBtBNSrkPAIQQiwAMh/vhgt3PwT4AdwKY7vn7EgDemQoWALgRgIT7bkIBcEgIkSmEOElj3dnxKngU1I5ZCCFuh7vW9RTc3+9UOeZv4J4lysuB1P+ctY45Lp9zstWse6EjTQAATiFEsl1QzGoC8BaAmwA8CuBTzzKvegC9kQLnQEr5LYB2v0Vpni8uoH2c3uVq6yY9lWPeAOBZKeU1APYD+AdS6Jg1pvZL6c9Z45jj9jknW7CuA9DT7+90KaVDa2Wb2QPgcymlIqXcA/eH2dfv9Z4AapCa58A/L6d1nN7lauva0Wwp5WbvvwFcjBQ7Zs/UfssBTJdSfoFO8DmrHHPcPudkC9Y5AEYAgBBiCAD1ed7t6SF48s9CiFMA9ADQKIQ4SwiRBneNezVS8xzkCSGGef59CzqO8yYhRLoQ4jS4L0pHNda1o0VCCO8Mq8MBbEYKHbMQ4mQAiwE85zcHa0p/zhrHHLfPOdlur2cDuEEIsRbuBPzvE1weK00BMFUIsQbup8EPwX2lnQF3Q/jFUsr1QoiNSL1z8DcA/yeE6ApgN4BZUkqnEGI1gFy4Kw2Pa62biAJb4M8AJggh2gCUA/ijlLIuhY75BQB9AIwVQoz1LHsSwPgU/pzVjvkZAO/G43NmpxgiIhtItjQIERGpYLAmIrIBBmsiIhtgsCYisgEGayIiG2CwJiKyAQZrIiIbYLAmIrKB/w8vFfM9ZQUg2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a295686630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean discriminator loss : 2.2773863199949265\n",
      "Std discriminator loss :  0.7070330677792672\n",
      "Min discriminator loss :  1.8584706783294678\n"
     ]
    }
   ],
   "source": [
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#sns.set_style('white')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(\"pretrain losses - srgan.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "# plot the generator loss values\n",
    "plt.plot(data['generator_loss'])\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean gan loss :\", np.mean(data['generator_loss']))\n",
    "print(\"Std gan loss : \", np.std(data['generator_loss']))\n",
    "print(\"Min gan loss : \", np.min(data['generator_loss']))\n",
    "\n",
    "# plot the PSNR loss values\n",
    "plt.plot(data['val_psnr'])\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean psnr loss :\", np.mean(data['val_psnr']))\n",
    "print(\"Std psnr loss : \", np.std(data['val_psnr']))\n",
    "print(\"Min psnr loss : \", np.min(data['val_psnr']))\n",
    "\n",
    "with open(\"pretrain losses - discriminator.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Data loaded.\")\n",
    "\n",
    "# plot the discriminator loss values\n",
    "plt.plot(data['discriminator_loss'])\n",
    "plt.show()\n",
    "\n",
    "print(\"Mean discriminator loss :\", np.mean(data['discriminator_loss']))\n",
    "print(\"Std discriminator loss : \", np.std(data['discriminator_loss']))\n",
    "print(\"Min discriminator loss : \", np.min(data['discriminator_loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model on Set 5 Validation images\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "integer division or modulo by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0fdd3868cadb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    300\u001b[0m     \u001b[1;31m#sr_resnet_test.train_model(coco_path, num_images=50000, epochs=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m     \u001b[0mtest_set5\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr_resnet_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m     \u001b[0mtest_set14\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr_resnet_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[0mtest_bsd100\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msr_resnet_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_width\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg_height\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0fdd3868cadb>\u001b[0m in \u001b[0;36mtest_set5\u001b[1;34m(model, img_width, img_height, batch_size)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing model on Set 5 Validation images\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     total_psnr = _test_loop(set5_path, batch_size, datagen, img_height, img_width, iteration, large_img_height, large_img_width,\n\u001b[1;32m---> 46\u001b[1;33m                             model, total_psnr, \"set5\", 5)\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Average PSNR of Set5 validation images : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_psnr\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-0fdd3868cadb>\u001b[0m in \u001b[0;36m_test_loop\u001b[1;34m(path, batch_size, datagen, img_height, img_width, iteration, large_img_height, large_img_width, model, total_psnr, prefix, num_images)\u001b[0m\n\u001b[0;32m     84\u001b[0m                total_psnr, prefix, num_images):\n\u001b[0;32m     85\u001b[0m     for x in datagen.flow_from_directory(path, class_mode=None, batch_size=batch_size,\n\u001b[1;32m---> 86\u001b[1;33m                                          target_size=(large_img_width, large_img_height)):\n\u001b[0m\u001b[0;32m     87\u001b[0m         \u001b[0mt1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\stable\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    833\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 834\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    836\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\stable\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1184\u001b[0m         \"\"\"\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0mindex_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\anaconda\\envs\\stable\\lib\\site-packages\\keras\\preprocessing\\image.py\u001b[0m in \u001b[0;36m_flow_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    817\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_index_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m             \u001b[0mcurrent_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    820\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcurrent_index\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_index\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: integer division or modulo by zero"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "#import models\n",
    "from loss import PSNRLoss, psnr\n",
    "\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "from imageio import imwrite as imsave\n",
    "from skimage.transform import resize as imresize\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "\n",
    "base_weights_path = \"weights/\"\n",
    "base_val_images_path = \"val_images/\"\n",
    "base_test_images = \"test_images/\"\n",
    "\n",
    "set5_path = r\"tests\\set5\"\n",
    "set14_path = r\"tests\\set14\"\n",
    "bsd100_path = r\"tests\\bsd100\"\n",
    "\n",
    "if not os.path.exists(base_weights_path):\n",
    "    os.makedirs(base_weights_path)\n",
    "\n",
    "if not os.path.exists(base_val_images_path):\n",
    "    os.makedirs(base_val_images_path)\n",
    "\n",
    "if not os.path.exists(base_test_images):\n",
    "    os.makedirs(base_test_images)\n",
    "\n",
    "def test_set5(model : Model, img_width=32, img_height=32, batch_size=1):\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    large_img_width = img_width * 4\n",
    "    large_img_height = img_height * 4\n",
    "\n",
    "    iteration = 0\n",
    "    total_psnr = 0.0\n",
    "\n",
    "    print(\"Testing model on Set 5 Validation images\")\n",
    "    total_psnr = _test_loop(set5_path, batch_size, datagen, img_height, img_width, iteration, large_img_height, large_img_width,\n",
    "                            model, total_psnr, \"set5\", 5)\n",
    "\n",
    "    print(\"Average PSNR of Set5 validation images : \", total_psnr / 5)\n",
    "    print()\n",
    "\n",
    "\n",
    "def test_set14(model : Model, img_width=32, img_height=32, batch_size=1):\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    large_img_width = img_width * 4\n",
    "    large_img_height = img_height * 4\n",
    "\n",
    "    iteration = 0\n",
    "    total_psnr = 0.0\n",
    "\n",
    "    print(\"Testing model on Set 14 Validation images\")\n",
    "    total_psnr = _test_loop(set14_path, batch_size, datagen, img_height, img_width, iteration, large_img_height,\n",
    "                            large_img_width, model, total_psnr, \"set14\", 14)\n",
    "\n",
    "    print(\"Average PSNR of Set5 validation images : \", total_psnr / 14)\n",
    "    print()\n",
    "\n",
    "def test_bsd100(model : Model, img_width=32, img_height=32, batch_size=1):\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    large_img_width = img_width * 4\n",
    "    large_img_height = img_height * 4\n",
    "\n",
    "    iteration = 0\n",
    "    total_psnr = 0.0\n",
    "\n",
    "    print(\"Testing model on BSD 100 Validation images\")\n",
    "    total_psnr = _test_loop(bsd100_path, batch_size, datagen, img_height, img_width, iteration, large_img_height, large_img_width,\n",
    "                            model, total_psnr, \"bsd100\", 100)\n",
    "\n",
    "    print(\"Average PSNR of BSD100 validation images : \", total_psnr / 100)\n",
    "    print()\n",
    "\n",
    "\n",
    "def _test_loop(path, batch_size, datagen, img_height, img_width, iteration, large_img_height, large_img_width, model,\n",
    "               total_psnr, prefix, num_images):\n",
    "    for x in datagen.flow_from_directory(path, class_mode=None, batch_size=batch_size,\n",
    "                                         target_size=(large_img_width, large_img_height)):\n",
    "        t1 = time.time()\n",
    "\n",
    "        # resize images\n",
    "        x_temp = x.copy()\n",
    "        x_temp = x_temp.transpose((0, 2, 3, 1))\n",
    "\n",
    "        x_generator = np.empty((batch_size, img_width, img_height, 3))\n",
    "\n",
    "        for j in range(batch_size):\n",
    "            img = imresize(x_temp[j], (img_width, img_height))\n",
    "            x_generator[j, :, :, :] = img\n",
    "\n",
    "        x_generator = x_generator.transpose((0, 3, 1, 2))\n",
    "\n",
    "        output_image_batch = model.predict_on_batch(x_generator)\n",
    "\n",
    "        average_psnr = 0.0\n",
    "        for x_i in range(batch_size):\n",
    "            average_psnr += psnr(x[x_i], output_image_batch[x_i] / 255.)\n",
    "            total_psnr += average_psnr\n",
    "\n",
    "        average_psnr /= batch_size\n",
    "\n",
    "        iteration += batch_size\n",
    "        t2 = time.time()\n",
    "\n",
    "        print(\"Time required : %0.2f. Average validation PSNR over %d samples = %0.2f\" %\n",
    "              (t2 - t1, batch_size, average_psnr))\n",
    "\n",
    "        for x_i in range(batch_size):\n",
    "            real_path = base_test_images + prefix + \"_iteration_%d_num_%d_real_.png\" % (iteration, x_i + 1)\n",
    "            generated_path = base_test_images + prefix + \"_iteration_%d_num_%d_generated.png\" % (iteration, x_i + 1)\n",
    "\n",
    "            val_x = x[x_i].copy() * 255.\n",
    "            val_x = val_x.transpose((1, 2, 0))\n",
    "            val_x = np.clip(val_x, 0, 255).astype('uint8')\n",
    "\n",
    "            output_image = output_image_batch[x_i]\n",
    "            output_image = output_image.transpose((1, 2, 0))\n",
    "            output_image = np.clip(output_image, 0, 255).astype('uint8')\n",
    "\n",
    "            imsave(real_path, val_x[:,:,0])\n",
    "            imsave(generated_path, output_image[:,:,0])\n",
    "\n",
    "        if iteration >= num_images:\n",
    "            break\n",
    "    return total_psnr\n",
    "\n",
    "\n",
    "class SRResNetTest:\n",
    "\n",
    "    def __init__(self, img_width=96, img_height=96, batch_size=16):\n",
    "        assert img_width >= 16, \"Minimum image width must be at least 16\"\n",
    "        assert img_height >= 16, \"Minimum image height must be at least 16\"\n",
    "\n",
    "        self.img_width = img_width\n",
    "        self.img_height = img_height\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.model = None # type: Model\n",
    "        self.weights_path = base_weights_path + \"sr_resnet_weights.h5\"\n",
    "\n",
    "    def build_model(self, load_weights=False) -> Model:\n",
    "        sr_resnet = GenerativeNetwork(self.img_width, self.img_height, self.batch_size)\n",
    "\n",
    "        ip = Input(shape=(self.img_width, self.img_height, 3), name='x_generator')\n",
    "        output = sr_resnet.create_sr_model(ip)\n",
    "\n",
    "        self.model = Model(ip, output)\n",
    "\n",
    "        optimizer = Adam(lr=1e-4)\n",
    "        self.model.compile(optimizer, loss='mse', metrics=[PSNRLoss])\n",
    "\n",
    "        if load_weights:\n",
    "            try:\n",
    "                self.model.load_weights(self.weights_path)\n",
    "                print(\"SR ResNet model weights loaded.\")\n",
    "            except Exception:\n",
    "                print(\"Weight for SR ResNet model not found or are incorrect size. Cannot load weights.\")\n",
    "\n",
    "                response = input(\"Continue without loading weights? 'y' or 'n' \")\n",
    "                if response == 'n':\n",
    "                    exit()\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def train_model(self, image_dir, num_images=50000, epochs=1):\n",
    "        datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "        img_width = self.img_width * 4\n",
    "        img_height = self.img_height * 4\n",
    "\n",
    "        early_stop = False\n",
    "        iteration = 0\n",
    "        prev_improvement = -1\n",
    "\n",
    "        print(\"Training SR ResNet network\")\n",
    "        for i in range(epochs):\n",
    "            print()\n",
    "            print(\"Epoch : %d\" % (i + 1))\n",
    "\n",
    "            for x in datagen.flow_from_directory(image_dir, class_mode=None, batch_size=self.batch_size,\n",
    "                                                 target_size=(img_width, img_height)):\n",
    "\n",
    "                try:\n",
    "                    t1 = time.time()\n",
    "\n",
    "                    # resize images\n",
    "                    x_temp = x.copy()\n",
    "                    x_temp = x_temp.transpose((0, 2, 3, 1))\n",
    "\n",
    "                    x_generator = np.empty((self.batch_size, self.img_width, self.img_height, 3))\n",
    "\n",
    "                    for j in range(self.batch_size):\n",
    "                        img = gaussian_filter(x_temp[j], sigma=0.5)\n",
    "                        img = imresize(img, (self.img_width, self.img_height,3))\n",
    "                        x_generator[j, :, :, :] = img\n",
    "\n",
    "                    #x_generator = x_generator.transpose((0, 3, 1, 2))\n",
    "\n",
    "                    if iteration % 50 == 0 and iteration != 0 :\n",
    "                        print(\"Random Validation image..\")\n",
    "                        output_image_batch = self.model.predict_on_batch(x_generator)\n",
    "\n",
    "                        print(\"Pred Max / Min: %0.2f / %0.2f\" % (output_image_batch.max(),\n",
    "                                                                 output_image_batch.min()))\n",
    "\n",
    "                        average_psnr = 0.0\n",
    "                        for x_i in range(self.batch_size):\n",
    "                            average_psnr += psnr(x[x_i], output_image_batch[x_i] / 255.)\n",
    "\n",
    "                        average_psnr /= self.batch_size\n",
    "\n",
    "                        iteration += self.batch_size\n",
    "                        t2 = time.time()\n",
    "\n",
    "                        print(\"Time required : %0.2f. Average validation PSNR over %d samples = %0.2f\" %\n",
    "                              (t2 - t1, self.batch_size, average_psnr))\n",
    "\n",
    "                        for x_i in range(self.batch_size):\n",
    "                            real_path = base_val_images_path + \"epoch_%d_iteration_%d_num_%d_real_.png\" % \\\n",
    "                                                               (i + 1, iteration, x_i + 1)\n",
    "\n",
    "                            generated_path = base_val_images_path + \\\n",
    "                                             \"epoch_%d_iteration_%d_num_%d_generated.png\" % (i + 1,\n",
    "                                                                                            iteration,\n",
    "                                                                                            x_i + 1)\n",
    "\n",
    "                            val_x = x[x_i].copy() * 255.\n",
    "                            val_x = val_x.transpose((1, 2, 0))\n",
    "                            val_x = np.clip(val_x, 0, 255).astype('uint8')\n",
    "\n",
    "                            output_image = output_image_batch[x_i]\n",
    "                            output_image = output_image.transpose((1, 2, 0))\n",
    "                            output_image = np.clip(output_image, 0, 255).astype('uint8')\n",
    "\n",
    "                            imsave(real_path, val_x[:,:,0])\n",
    "                            imsave(generated_path, output_image[:,:,0])\n",
    "\n",
    "                        '''\n",
    "                        Don't train of validation images for now.\n",
    "\n",
    "                        Note that if epochs > 1, there is a chance that\n",
    "                        validation images may be used for training purposes as well.\n",
    "\n",
    "                        In that case, this isn't strictly a validation measure, instead of\n",
    "                        just a check to see what the network has learned.\n",
    "                        '''\n",
    "                        continue\n",
    "\n",
    "                    hist = self.model.fit(x_generator, x * 255, batch_size=self.batch_size, epochs=1, verbose=0)\n",
    "                    psnr_loss_val = hist.history['PSNRLoss'][0]\n",
    "\n",
    "                    if prev_improvement == -1:\n",
    "                        prev_improvement = psnr_loss_val\n",
    "\n",
    "                    improvement = (prev_improvement - psnr_loss_val) / prev_improvement * 100\n",
    "                    prev_improvement = psnr_loss_val\n",
    "\n",
    "                    iteration += self.batch_size\n",
    "                    t2 = time.time()\n",
    "\n",
    "                    print(\"%d / %d | Improvement : %0.2f %% | Time required : %0.2f s/step | \"\n",
    "                          \"PSNR : %0.3f\" % (iteration, num_images, improvement, t2 - t1, psnr_loss_val))\n",
    "\n",
    "                    if iteration % 1000 == 0 and iteration != 0:\n",
    "                        print(\"Saving weights\")\n",
    "                        self.model.save_weights(self.weights_path, overwrite=True)\n",
    "\n",
    "                    if iteration >= num_images:\n",
    "                        break\n",
    "\n",
    "                except KeyboardInterrupt:\n",
    "                    print(\"Keyboard interrupt detected. Stopping early.\")\n",
    "                    early_stop = True\n",
    "                    break\n",
    "\n",
    "            iteration = 0\n",
    "\n",
    "            if early_stop:\n",
    "                break\n",
    "\n",
    "        print(\"Finished training SRGAN network. Saving model weights.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from keras.utils.vis_utils import plot_model as plot\n",
    "\n",
    "    coco_path = r\"D:\\dataset\\coco2014\"\n",
    "\n",
    "    img_width = img_height = 64\n",
    "\n",
    "    sr_resnet_test = SRResNetTest(img_width=img_width, img_height=img_height, batch_size=1)\n",
    "    sr_resnet_test.build_model(load_weights=False)\n",
    "    #plot(sr_resnet_test.model, to_file='sr_resnet.png', show_shapes=True)\n",
    "\n",
    "    #sr_resnet_test.train_model(coco_path, num_images=50000, epochs=1)\n",
    "\n",
    "    test_set5(sr_resnet_test.model, img_width=img_width, img_height=img_height)\n",
    "    test_set14(sr_resnet_test.model, img_width=img_width, img_height=img_height)\n",
    "    test_bsd100(sr_resnet_test.model, img_width=img_width, img_height=img_height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
