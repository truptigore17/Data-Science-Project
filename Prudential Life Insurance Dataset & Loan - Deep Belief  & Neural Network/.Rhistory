rm(list=ls(all=TRUE))
x1s <- c(.5,1,1,2,3,3.5,0,1,-1.2,0,1,3.5,4,5,5.5,6)
x2s <- c(3.5,1,2.5,2,1,1.2,2,1,-1.2,0,5.8,3,4,5,4,1)
ys <- c(rep(+1,8),          rep(-1,8))
my.data <- data.frame(x1=x1s, x2=x2s, type=as.factor(ys))
my.data
library('e1071')
# use one of the following two options
svm.model <- svm(type ~ ., data=my.data,
type='C-classification', kernel='linear', scale=FALSE, cost = 10000) # cost = 1
svm.model
#svm.model <- svm(type ~ ., data=my.data,
# type='C-classification', kernel='linear', scale=FALSE, cost = 0.5)
#svm.model
# svm.model$index is the indices of support vectors
plot(my.data[,-3],col=(ys+3)/2, pch=19, xlim=c(-1,6), ylim=c(-1,6))
points(my.data[svm.model$index,c(1,2)],col="blue",cex=2)
x1min = min(x1s); x1max = max(x1s);
x2min = min(x2s); x2max = max(x2s);
coef1 = sum(svm.model$coefs*x1s[svm.model$index]);
coef2 = sum(svm.model$coefs*x2s[svm.model$index]);
lines(c(x1min,x1max),  (svm.model$rho-coef1*c(x1min, x1max))/coef2)
lines(c(x1min,x1max),  (svm.model$rho+1-coef1*c(x1min, x1max))/coef2, lty=2)
lines(c(x1min,x1max),  (svm.model$rho-1-coef1*c(x1min, x1max))/coef2, lty=2)
# http://stackoverflow.com/questions/21827776/plot-margins-for-support-vector-machine
rm(list=ls(all=TRUE))
x1s <- c(.5,1,1,2,3,3.5,0,1,-1.2,0,1,3.5,4,5,5.5,6)
x2s <- c(3.5,1,2.5,2,1,1.2,2,1,-1.2,0,5.8,3,4,5,4,1)
ys <- c(rep(+1,8),          rep(-1,8))
my.data <- data.frame(x1=x1s, x2=x2s, type=as.factor(ys))
my.data
library('e1071')
# use one of the following two options
svm.model <- svm(type ~ ., data=my.data,
type='C-classification', kernel='radial', scale=FALSE, cost = 10000) # cost = 1
svm.model
#svm.model <- svm(type ~ ., data=my.data,
# type='C-classification', kernel='linear', scale=FALSE, cost = 0.5)
#svm.model
# svm.model$index is the indices of support vectors
plot(my.data[,-3],col=(ys+3)/2, pch=19, xlim=c(-1,6), ylim=c(-1,6))
points(my.data[svm.model$index,c(1,2)],col="blue",cex=2)
x1min = min(x1s); x1max = max(x1s);
x2min = min(x2s); x2max = max(x2s);
coef1 = sum(svm.model$coefs*x1s[svm.model$index]);
coef2 = sum(svm.model$coefs*x2s[svm.model$index]);
lines(c(x1min,x1max),  (svm.model$rho-coef1*c(x1min, x1max))/coef2)
lines(c(x1min,x1max),  (svm.model$rho+1-coef1*c(x1min, x1max))/coef2, lty=2)
lines(c(x1min,x1max),  (svm.model$rho-1-coef1*c(x1min, x1max))/coef2, lty=2)
# http://stackoverflow.com/questions/21827776/plot-margins-for-support-vector-machine
rm(list=ls(all=TRUE))
x1s <- c(.5,1,1,2,3,3.5,0,1,-1.2,0,1,3.5,4,5,5.5,6)
x2s <- c(3.5,1,2.5,2,1,1.2,2,1,-1.2,0,5.8,3,4,5,4,1)
ys <- c(rep(+1,8),          rep(-1,8))
my.data <- data.frame(x1=x1s, x2=x2s, type=as.factor(ys))
my.data
library('e1071')
# use one of the following two options
svm.model <- svm(type ~ ., data=my.data,
type='C-classification', kernel='radial', gamma=0.1,scale=FALSE, cost = 10000) # cost = 1
svm.model
#svm.model <- svm(type ~ ., data=my.data,
# type='C-classification', kernel='linear', scale=FALSE, cost = 0.5)
#svm.model
# svm.model$index is the indices of support vectors
plot(my.data[,-3],col=(ys+3)/2, pch=19, xlim=c(-1,6), ylim=c(-1,6))
points(my.data[svm.model$index,c(1,2)],col="blue",cex=2)
x1min = min(x1s); x1max = max(x1s);
x2min = min(x2s); x2max = max(x2s);
coef1 = sum(svm.model$coefs*x1s[svm.model$index]);
coef2 = sum(svm.model$coefs*x2s[svm.model$index]);
lines(c(x1min,x1max),  (svm.model$rho-coef1*c(x1min, x1max))/coef2)
lines(c(x1min,x1max),  (svm.model$rho+1-coef1*c(x1min, x1max))/coef2, lty=2)
lines(c(x1min,x1max),  (svm.model$rho-1-coef1*c(x1min, x1max))/coef2, lty=2)
# http://stackoverflow.com/questions/21827776/plot-margins-for-support-vector-machine
rm(list=ls(all=TRUE))
x1s <- c(.5,1,1,2,3,3.5,0,1,-1.2,0,1,3.5,4,5,5.5,6)
x2s <- c(3.5,1,2.5,2,1,1.2,2,1,-1.2,0,5.8,3,4,5,4,1)
ys <- c(rep(+1,8),          rep(-1,8))
my.data <- data.frame(x1=x1s, x2=x2s, type=as.factor(ys))
my.data
library('e1071')
# use one of the following two options
svm.model <- svm(type ~ ., data=my.data,
type='C-classification', kernel='radial', gamma=1,scale=FALSE, cost = 10000) # cost = 1
svm.model
#svm.model <- svm(type ~ ., data=my.data,
# type='C-classification', kernel='linear', scale=FALSE, cost = 0.5)
#svm.model
# svm.model$index is the indices of support vectors
plot(my.data[,-3],col=(ys+3)/2, pch=19, xlim=c(-1,6), ylim=c(-1,6))
points(my.data[svm.model$index,c(1,2)],col="blue",cex=2)
x1min = min(x1s); x1max = max(x1s);
x2min = min(x2s); x2max = max(x2s);
coef1 = sum(svm.model$coefs*x1s[svm.model$index]);
coef2 = sum(svm.model$coefs*x2s[svm.model$index]);
lines(c(x1min,x1max),  (svm.model$rho-coef1*c(x1min, x1max))/coef2)
lines(c(x1min,x1max),  (svm.model$rho+1-coef1*c(x1min, x1max))/coef2, lty=2)
lines(c(x1min,x1max),  (svm.model$rho-1-coef1*c(x1min, x1max))/coef2, lty=2)
# https://www.r-bloggers.com/hierarchical-clustering-in-r-2/
#install.packages("ggplot2")
#install.packages("XLConnect")
library(ggplot2)
library(XLConnect)
play <- readWorksheetFromFile("C:/Users/Trupti/Desktop/play.xlsx", sheet = 1)
# complete linkage
clusters <- hclust(dist(play[, 2:3]))
plot(clusters)
clusterCut <- cutree(clusters, 2)
table(clusterCut, play$Decision)
# mean/average linkage
clusters <- hclust(dist(play[, 2:3]), method = 'average')
plot(clusters)
clusterCut <- cutree(clusters, 2)
table(clusterCut, play$Decision)
ggplot(play, aes(play$Temperature, play$Humidity, color = play$Decision)) +
geom_point(alpha = 0.4, size = 3.5) + geom_point(col = clusterCut) +
scale_color_manual(values = c('black', 'red', 'green'))
# https://www.r-bloggers.com/hierarchical-clustering-in-r-2/
#install.packages("ggplot2")
#install.packages("XLConnect")
library(ggplot2)
library(XLConnect)
play <- readWorksheetFromFile("C:/Users/Trupti/Desktop/play.xlsx", sheet = 1)
# complete linkage
clusters <- hclust(dist(play[, 2:3]))
plot(clusters)
clusterCut <- cutree(clusters, 2)
table(clusterCut, play$Decision)
# mean/average linkage
clusters <- hclust(dist(play[, 2:3]), method = 'average')
plot(clusters)
clusterCut <- cutree(clusters, 2)
table(clusterCut, play$Decision)
ggplot(play, aes(play$Temperature, play$Humidity, color = play$Decision)) +
geom_point(alpha = 0.4, size = 3.5) + geom_point(col = clusterCut) +
scale_color_manual(values = c('black', 'red', 'green'))
data(GermanCredit)
write.csv(Germancredit, file="Germancredit.csv")
data(GermanCredit)
Germancredit
library(caret)
library(e1071)
data(GermanCredit)
Germancredit
data(GermanCredit)
dataset = GermanCredit
write.csv(dataset, file="Germancredit.csv")
getwd
getwd
getwd()
###########################################################
######### Please fill the ??? with proper description (atleast 130 charaters for each)
######### for SVM function try different values to achieve better results
# loading neccessary packages and dataset
install.packages("caret")
install.packages("e1701")
install.packages("caret")
library(caret)
library(e1071)
data(GermanCredit)
dataset = GermanCredit
write.csv(dataset, file="Germancredit.csv")
getwd()
# ???
str(dataset)
dataset[,1:7] = as.data.frame(lapply(dataset[,1:7], scale))
str(dataset)
dataset
write.csv(dataset, file="dataset.csv")
# ???
sample_index = sample(1000, 200)
test_dateset = dataset[sample_index,]
train_dateset = dataset[-sample_index,]
# ???
#model = svm(Class ~ ., kernel = ???, cost = ???, gamma = ???, data = train_dateset, scale = F)
model = svm(Class ~ ., kernel = "linear", cost = 0.5, data = train_dateset, scale = F)
#model = svm(Class ~ ., kernel = "radial", cost = 0.5, gamma = 10, data = train_dateset, scale = F)
# ???
predictions <-  predict(model, test_dateset[-10])
# ???
table(test_dateset[,10], predictions)
model = svm(Class ~ ., kernel = "radial", cost = 0.5, gamma = 10, data = train_dateset, scale = F)
# ???
predictions <-  predict(model, test_dateset[-10])
# ???
table(test_dateset[,10], predictions)
summary(predictions)
model = svm(Class ~ ., kernel = "radial", cost = 0.5, gamma = 1, data = train_dateset, scale = F)
# ???
predictions <-  predict(model, test_dateset[-10])
# ???
table(test_dateset[,10], predictions)
library(caret)
x<-subset(train_dateset, select = -Class)
y<- train_dateset$Class
model<-svm(x,y, scale=F)
obj<-tune(svm, Class~.,kernel ="linear", data= train_dateset, ranges=list(cost=2^(-5:15)))
summary(obj)
summary(obj)
library(e1071)
obj<-tune(svm, Class~.,kernel ="linear", data= train_dateset, cost=2^(-5:15))
summary(obj)
#install.packages("caret")
#install.packages("e1701")
library(caret)
library(e1071)
data(GermanCredit)
dataset = GermanCredit
str(dataset)
dataset[,1:7] = as.data.frame(lapply(dataset[,1:7], scale))
str(dataset)
dataset
#write.csv(dataset, file="dataset.csv")
# ???
sample_index = sample(1000, 200)
test_dateset = dataset[sample_index,]
train_dateset = dataset[-sample_index,]
obj<-tune.svm(Class~.,kernel ="linear", data= train_dateset, cost=2^(-5:10))
summary(obj)
model = svm(Class ~ ., kernel = "radial", cost = 2,gamma=0.0625, data = train_dateset, scale = F)
model = svm(Class ~ ., kernel = "radial", cost = 2,gamma=0.0625, data = train_dateset, scale = F)
predictions <-  predict(model, test_dateset[-10])
# ???
table(test_dateset[,10], predictions)
install.packages("ade4")
#install.packages("neuralnet")
#install.packages("ISLR")
getwd()
setwd("E:/ADS/Class Practise")
# Read CSV into R
require(XLConnect)
library(xlsx)
loan= read.xlsx("loan.xlsx",sheetIndex = 1)
#Convert to Numeric
loan$Res_status<-as.numeric(loan$Res_status)-1
loan$Occupation<- as.numeric(loan$Occupation)-1
loan$Job_Status<-as.numeric(loan$Job_status)-1
loan$Liab_red<- as.numeric(loan$Liab_ref)-1
loan$Acc_ref<-as.numeric(loan$Acc_ref)-1
loan$Decision<-as.numeric(loan$Decision)-1
#Move required columns to one dataframe
myloan<-loan[c("Res_status","Occupation","Job_Status","Liab_red","Acc_ref","Decision")]
library(ISLR)
library(neuralnet)
print(head(myloan))
#Separate Train and Test data
x<-sample(1:nrow(myloan), nrow(myloan)*0.90)
train_ <- myloan[x,]
test_ <- myloan[-x,]
#apply neural network
nn <- neuralnet(train_$Decision ~ train_$Res_status+train_$Occupation+train_$Job_Status+train_$Liab_red+train_$Acc_ref,data=train_, hidden=c(2,2,2),linear.output=FALSE)
predicted.nn.values <- compute(nn,test_[1:5])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
table(test_$Decision,predicted.nn.values$net.result)
predicted.nn.values$net.result
#Plot Neural Network
plot(nn)
nn <- neuralnet(train_$Decision ~ train_$Res_status+train_$Occupation+train_$Job_Status+train_$Liab_red+train_$Acc_ref,data=train_, hidden=c(2,2,2),linear.output=FALSE)
nn <- neuralnet(train_$Decision ~ train_$Res_status+train_$Occupation+train_$Job_Status+train_$Liab_red+train_$Acc_ref,data=train_, hidden=c(2,2,2),linear.output=FALSE, stepmax = 1e6)
predicted.nn.values <- compute(nn,test_[1:5])
predicted.nn.values$net.result <- sapply(predicted.nn.values$net.result,round,digits=0)
table(test_$Decision,predicted.nn.values$net.result)
predicted.nn.values$net.result
plot(nn)
#Install required package
#install.packages("forecast")
#install.packages("ade4")
#install.packages("forecastHybrid")
library(forecast)
library(ade4)
library(e1071)
library(ggplot2)
library("rpart")
library("rpart.plot")
library("neuralnet")
library("ISLR")
getwd()
setwd("E:/ADS/Assignment/Assignment 6")
# Read CSV into R
mydata <- read.csv(file="train.csv", header=TRUE, sep=",")
options(max.print=1000000)
#Pre-processing starts here
#Deleting columns with empty cells more than 60%
mydata$Family_Hist_3 <- NULL
mydata$Family_Hist_5 <- NULL
mydata$Medical_History_10 <- NULL
mydata$Medical_History_15 <- NULL
mydata$Medical_History_24 <- NULL
mydata$Medical_History_32 <- NULL
mydata$Id <- NULL
#Filling missing values with mean value for Employment_Info_1
mydata$Employment_Info_1[is.na(mydata$Employment_Info_1)] <- mean(mydata$Employment_Info_1, na.rm = T)
#Filling missing values with mean value for Employment_Info_4
mydata$Employment_Info_4[is.na(mydata$Employment_Info_4)] <- mean(mydata$Employment_Info_4, na.rm = T)
#Filling missing values with mean value for Employment_Info_6
mydata$Employment_Info_6[is.na(mydata$Employment_Info_6)] <- mean(mydata$Employment_Info_6, na.rm = T)
#Filling missing values with mean value for Insurance_History_5
mydata$Insurance_History_5[is.na(mydata$Insurance_History_5)] <- mean(mydata$Insurance_History_5, na.rm = T)
#Filling missing values with mean value for Family_Hist_2
mydata$Family_Hist_2[is.na(mydata$Family_Hist_2)] <- mean(mydata$Family_Hist_2, na.rm = T)
#Filling missing values with mean value for Family_Hist_4
mydata$Family_Hist_4[is.na(mydata$Family_Hist_4)] <- mean(mydata$Family_Hist_4, na.rm = T)
#Filling missing values with mean value for Medical_History_1
mydata$Medical_History_1[is.na(mydata$Medical_History_1)] <- mean(mydata$Medical_History_1, na.rm = T)
#Convert Categorical using 1 to C Coding
data_ctgr <- mydata[c("Medical_History_1","Product_Info_1", "Product_Info_2", "Product_Info_3", "Product_Info_5", "Product_Info_6", "Product_Info_7", "Employment_Info_2", "Employment_Info_3", "Employment_Info_5", "InsuredInfo_1", "InsuredInfo_2", "InsuredInfo_3", "InsuredInfo_4", "InsuredInfo_5", "InsuredInfo_6", "InsuredInfo_7", "Insurance_History_1", "Insurance_History_2", "Insurance_History_3", "Insurance_History_4", "Insurance_History_7", "Insurance_History_8", "Insurance_History_9", "Family_Hist_1", "Medical_History_2", "Medical_History_3", "Medical_History_4", "Medical_History_5", "Medical_History_6", "Medical_History_7", "Medical_History_8", "Medical_History_9", "Medical_History_11", "Medical_History_12", "Medical_History_13", "Medical_History_14", "Medical_History_16", "Medical_History_17", "Medical_History_18", "Medical_History_19", "Medical_History_20", "Medical_History_21", "Medical_History_22", "Medical_History_23", "Medical_History_25", "Medical_History_26", "Medical_History_27", "Medical_History_28", "Medical_History_29", "Medical_History_30", "Medical_History_31", "Medical_History_33", "Medical_History_34", "Medical_History_35", "Medical_History_36", "Medical_History_37", "Medical_History_38", "Medical_History_39", "Medical_History_40", "Medical_History_41")]
OneToCconv <- acm.disjonctif(data_ctgr)
#Prepare the data
data_cntg <- mydata[c("Product_Info_4", "Ins_Age", "Ht", "Wt", "BMI", "Employment_Info_1", "Employment_Info_4", "Employment_Info_6", "Insurance_History_5", "Family_Hist_2", "Family_Hist_4")]
data_dummy<-mydata[c("Medical_Keyword_1","Medical_Keyword_2","Medical_Keyword_3","Medical_Keyword_4","Medical_Keyword_5","Medical_Keyword_6","Medical_Keyword_7","Medical_Keyword_8","Medical_Keyword_9","Medical_Keyword_10","Medical_Keyword_11","Medical_Keyword_12","Medical_Keyword_13","Medical_Keyword_14","Medical_Keyword_15","Medical_Keyword_16","Medical_Keyword_17","Medical_Keyword_18","Medical_Keyword_19", "Medical_Keyword_20", "Medical_Keyword_21", "Medical_Keyword_22", "Medical_Keyword_23","Medical_Keyword_24", "Medical_Keyword_25", "Medical_Keyword_26", "Medical_Keyword_27", "Medical_Keyword_28", "Medical_Keyword_29","Medical_Keyword_30", "Medical_Keyword_31", "Medical_Keyword_32", "Medical_Keyword_33","Medical_Keyword_34", "Medical_Keyword_35","Medical_Keyword_36", "Medical_Keyword_37", "Medical_Keyword_38", "Medical_Keyword_39", "Medical_Keyword_40", "Medical_Keyword_41", "Medical_Keyword_42", "Medical_Keyword_43", "Medical_Keyword_44", "Medical_Keyword_45","Medical_Keyword_46", "Medical_Keyword_47","Medical_Keyword_48")]
final_data <- data.frame(c(OneToCconv, data_cntg,data_dummy))
Insurance<-data.frame(c(final_data, mydata[c("Response")]))
#Convert to Numeric
print(head(Insurance))
#Move required columns to one dataframe
myInsurance<-Insurance[c("BMI", "Product_Info_4","Medical_History_4.1","Medical_History_4.2","Medical_Keyword_3", "Response")]
print(head(myInsurance))
#Divide the given dataset
train1<-myInsurance[1:500,]
train2 <- acm.disjonctif(train1[c("Response")])
train<-data.frame(c(train1,train2))
train$Response <- NULL
print(head(train))
test<-myInsurance[49383:59382,]
nn <- neuralnet(train$Response.1+train$Response.2+train$Response.3+train$Response.4+train$Response.5+train$Response.6+train$Response.7+train$Response.8 ~ train$BMI+train$Product_Info_4+train$Medical_History_4.1+train$Medical_History_4.2+train$Medical_Keyword_3,data=train, hidden=c(2,2,2),linear.output=FALSE, stepmax = 1e6)
predicted.nn.values <- compute(nn,test[1:5])
responseResult<-predicted.nn.values$net.result
composedResponse<-apply(responseResult, 1,which.max)
head(composedResponse)
pred<- c('1','2','3','4','5','6','7','8')[composedResponse]
pred<- c('Response.1','2','3','4','5','6','7','8')[composedResponse]
predicted.nn.values <- compute(nn,test[1:5])
idx <- apply(predicted.neuralnetwork.values$net.result , 1, which.max)
idx <- apply(predicted.nn.values$net.result , 1, which.max)
pred <- c("1","2","3","4","5","6","7","8")[idx]
pred <- c("1","2","3","4","5","6","7","8")[idx]
nn <- neuralnet(train$Response.1+train$Response.2+train$Response.3+train$Response.4+train$Response.5+train$Response.6+train$Response.7+train$Response.8 ~ train$BMI+train$Product_Info_4+train$Medical_History_4.1+train$Medical_History_4.2+train$Medical_Keyword_3,data=train, hidden=c3,linear.output=FALSE, stepmax = 1e6)
nn <- neuralnet(train$Response.1+train$Response.2+train$Response.3+train$Response.4+train$Response.5+train$Response.6+train$Response.7+train$Response.8 ~ train$BMI+train$Product_Info_4+train$Medical_History_4.1+train$Medical_History_4.2+train$Medical_Keyword_3,data=train, hidden=c3,linear.output=FALSE, stepmax = 1e6)
nn <- neuralnet(train$Response.1+train$Response.2+train$Response.3+train$Response.4+train$Response.5+train$Response.6+train$Response.7+train$Response.8 ~ train$BMI+train$Product_Info_4+train$Medical_History_4.1+train$Medical_History_4.2+train$Medical_Keyword_3,data=train, hidden=c(3),linear.output=FALSE, stepmax = 1e6)
plot(nn)
predicted.nn.values <- compute(nn,test[1:5])
idx <- apply(predicted.nn.values$net.result , 1, which.max)
pred <- c("1","2","3","4","5","6","7","8")[idx]
predicted.nn.values <- compute(nn,test[2:53])
head(test)
predicted.nn.values <- compute(nn,test[1:5])
idx <- apply(predicted.nn.values$net.result , 1, which.max)
pred <- c("1","2","3","4","5","6","7","8")[idx]
pred <- data.frame("1","2","3","4","5","6","7","8")[idx]
head(idx)
pred <- data.frame( "id", "Response")[idx]
pred <- c( "id", "Response")[idx]
list_df = lapply(ls(), get)
names(list_df) = ls()
names(list_df) = ls()
predicted.nn.values$net.result
table(test$Response,predicted.nn.values$net.result)
head(idx)
pred1 <- c( "1","2","3","4","5","6","7","8")[idx]
pred1 <- c( "1","2","3","4","5","6","7","8")[[idx]]
pred1 <- c( "1","2","3","4","5","6","7","8", index.return = TRUE)[[idx]]
table(test$Response,predicted.nn.values$net.result)
pred <- c( "1","2","3","4","5","6","7","8", index.return = TRUE)[[idx]]
pred <- order( "1","2","3","4","5","6","7","8", index.return = TRUE)[[idx]]
pred <- factor(c( "1","2","3","4","5","6","7","8", index.return = TRUE))[idx]
pred <- factor(c( "1","2","3","4","5","6","7","8")[idx]
table(test$Response,predicted.nn.values$net.result)
predicted.nn.values$net.result
plot(nn)
pred <- factor(c( "1","2","3","4","5","6","7","8")[idx]
table(test$Response,predicted.nn.values$net.result)
predicted.nn.values$net.result
plot(nn)
pred <- c( "1","2","3","4","5","6","7","8")[idx]
pred <- c( "1","2","3","4","5","6","7","8")[idx]
pred <- factor(c( "1","2","3","4","5","6","7","8"))[idx]
pred <- factor(c( "1","2","3","4","5","6","7","8"))[idx]
idx <- apply(predicted.nn.values$net.result , 1, which.max)
head(idx)
pred <- factor(c( "1","2","3","4","5","6","7","8"))[idx]
pred <- factor(c( "1","2","3","4","5","6","7","8")[idx]
table(test$Response,predicted.nn.values$net.result)
predicted.nn.values$net.result
plot(nn)
pred <- factor(c( "1","2","3","4","5","6","7","8")[idx])
table(test$Response,predicted.nn.values$net.result)
pred <- factor(c( '1', '2','3','4','5','6','7','8')[idx])
install.packages("caTools")
library("caTools")
head(idx)
idx <- lapply(predicted.nn.values$net.result , 1, which.max)
idx <- sapply(predicted.nn.values$net.result , 1, which.max)
idx <- apply(predicted.nn.values$net.result , 1, which.max)
head(idx)
pred <- factor(c( '1', '2','3','4','5','6','7','8')[idx])
library("caTools")
pred <- c( '1', '2','3','4','5','6','7','8')[idx]
pred <- c( '1', '2','3','4','5','6','7','8')[idx]
pred <- c( '1', '2','3','4','5','6','7','8')[idx]
idx <- apply(predicted.nn.values$net.result , 2, which.max)
pred <- c( '1', '2','3','4','5','6','7','8')[idx]
table(test$Response,predicted.nn.values$net.result)
idx <- apply(predicted.nn.values$net.result , 2, which.max)
head(idx)
pred <- c( '1', '2','3','4','5','6','7','8')[idx]
head(pred)
idx <- apply(predicted.nn.values$net.result , 0, which.max)
idx <- apply(predicted.nn.values$net.result , 1, which.max)
head(idx)
pred <- c( '1', '2','3','4','5','6','7','8')[idx]
table(test$Response,predicted.nn.values$net.result)
head(test)
head(train)
table(test$Response,predicted.nn.values$net.result)
table(test$Response,predicted.nn.values$net.result)
predicted.nn.values$net.result
length(neural_model$model.list$variables)
length(nn$model.list$variables)
length(test_data[1:5])
length(test[1:5])
length(test[1,1:5])
head(pred)
table(test$Response,predicted.nn.values$net.result)
predicted.nn.values$net.result
options(max.print=1000000)
predicted.nn.values$net.result
#Install required package
#install.packages("forecast")
#install.packages("ade4")
#install.packages("forecastHybrid")
#install.packages("caTools")
library(forecast)
library(ade4)
library(e1071)
library(ggplot2)
library("rpart")
library("rpart.plot")
library("neuralnet")
library("ISLR")
library("caTools")
getwd()
setwd("E:/ADS/Assignment/Assignment 6")
# Read CSV into R
mydata <- read.csv(file="train.csv", header=TRUE, sep=",")
options(max.print=1000000)
#Pre-processing starts here
#Deleting columns with empty cells more than 60%
mydata$Family_Hist_3 <- NULL
mydata$Family_Hist_5 <- NULL
mydata$Medical_History_10 <- NULL
mydata$Medical_History_15 <- NULL
mydata$Medical_History_24 <- NULL
mydata$Medical_History_32 <- NULL
mydata$Id <- NULL
#Filling missing values with mean value for Employment_Info_1
mydata$Employment_Info_1[is.na(mydata$Employment_Info_1)] <- mean(mydata$Employment_Info_1, na.rm = T)
#Filling missing values with mean value for Employment_Info_4
mydata$Employment_Info_4[is.na(mydata$Employment_Info_4)] <- mean(mydata$Employment_Info_4, na.rm = T)
#Filling missing values with mean value for Employment_Info_6
mydata$Employment_Info_6[is.na(mydata$Employment_Info_6)] <- mean(mydata$Employment_Info_6, na.rm = T)
#Filling missing values with mean value for Insurance_History_5
mydata$Insurance_History_5[is.na(mydata$Insurance_History_5)] <- mean(mydata$Insurance_History_5, na.rm = T)
#Filling missing values with mean value for Family_Hist_2
mydata$Family_Hist_2[is.na(mydata$Family_Hist_2)] <- mean(mydata$Family_Hist_2, na.rm = T)
#Filling missing values with mean value for Family_Hist_4
mydata$Family_Hist_4[is.na(mydata$Family_Hist_4)] <- mean(mydata$Family_Hist_4, na.rm = T)
#Filling missing values with mean value for Medical_History_1
mydata$Medical_History_1[is.na(mydata$Medical_History_1)] <- mean(mydata$Medical_History_1, na.rm = T)
#Convert Categorical using 1 to C Coding
data_ctgr <- mydata[c("Medical_History_1","Product_Info_1", "Product_Info_2", "Product_Info_3", "Product_Info_5", "Product_Info_6", "Product_Info_7", "Employment_Info_2", "Employment_Info_3", "Employment_Info_5", "InsuredInfo_1", "InsuredInfo_2", "InsuredInfo_3", "InsuredInfo_4", "InsuredInfo_5", "InsuredInfo_6", "InsuredInfo_7", "Insurance_History_1", "Insurance_History_2", "Insurance_History_3", "Insurance_History_4", "Insurance_History_7", "Insurance_History_8", "Insurance_History_9", "Family_Hist_1", "Medical_History_2", "Medical_History_3", "Medical_History_4", "Medical_History_5", "Medical_History_6", "Medical_History_7", "Medical_History_8", "Medical_History_9", "Medical_History_11", "Medical_History_12", "Medical_History_13", "Medical_History_14", "Medical_History_16", "Medical_History_17", "Medical_History_18", "Medical_History_19", "Medical_History_20", "Medical_History_21", "Medical_History_22", "Medical_History_23", "Medical_History_25", "Medical_History_26", "Medical_History_27", "Medical_History_28", "Medical_History_29", "Medical_History_30", "Medical_History_31", "Medical_History_33", "Medical_History_34", "Medical_History_35", "Medical_History_36", "Medical_History_37", "Medical_History_38", "Medical_History_39", "Medical_History_40", "Medical_History_41")]
OneToCconv <- acm.disjonctif(data_ctgr)
#Prepare the data
data_cntg <- mydata[c("Product_Info_4", "Ins_Age", "Ht", "Wt", "BMI", "Employment_Info_1", "Employment_Info_4", "Employment_Info_6", "Insurance_History_5", "Family_Hist_2", "Family_Hist_4")]
data_dummy<-mydata[c("Medical_Keyword_1","Medical_Keyword_2","Medical_Keyword_3","Medical_Keyword_4","Medical_Keyword_5","Medical_Keyword_6","Medical_Keyword_7","Medical_Keyword_8","Medical_Keyword_9","Medical_Keyword_10","Medical_Keyword_11","Medical_Keyword_12","Medical_Keyword_13","Medical_Keyword_14","Medical_Keyword_15","Medical_Keyword_16","Medical_Keyword_17","Medical_Keyword_18","Medical_Keyword_19", "Medical_Keyword_20", "Medical_Keyword_21", "Medical_Keyword_22", "Medical_Keyword_23","Medical_Keyword_24", "Medical_Keyword_25", "Medical_Keyword_26", "Medical_Keyword_27", "Medical_Keyword_28", "Medical_Keyword_29","Medical_Keyword_30", "Medical_Keyword_31", "Medical_Keyword_32", "Medical_Keyword_33","Medical_Keyword_34", "Medical_Keyword_35","Medical_Keyword_36", "Medical_Keyword_37", "Medical_Keyword_38", "Medical_Keyword_39", "Medical_Keyword_40", "Medical_Keyword_41", "Medical_Keyword_42", "Medical_Keyword_43", "Medical_Keyword_44", "Medical_Keyword_45","Medical_Keyword_46", "Medical_Keyword_47","Medical_Keyword_48")]
final_data <- data.frame(c(OneToCconv, data_cntg,data_dummy))
Insurance<-data.frame(c(final_data, mydata[c("Response")]))
#Convert to Numeric
print(head(Insurance))
#Move required columns to one dataframe
myInsurance<-Insurance[c("BMI", "Product_Info_4","Medical_History_4.1","Medical_History_4.2","Medical_Keyword_3", "Response")]
print(head(myInsurance))
#Divide the given dataset
train1<-myInsurance[1:500,]
train2 <- acm.disjonctif(train1[c("Response")])
train<-data.frame(c(train1,train2))
train$Response <- NULL
print(head(train))
test<-myInsurance[49383:59382,]
head(test)
#neuralnetwork
nn <- neuralnet(train$Response.1+train$Response.2+train$Response.3+train$Response.4+train$Response.5+train$Response.6+train$Response.7+train$Response.8 ~ train$BMI+train$Product_Info_4+train$Medical_History_4.1+train$Medical_History_4.2+train$Medical_Keyword_3,data=train, hidden=c(3),linear.output=FALSE, stepmax = 1e6)
#Plot Neural Network
plot(nn)
plot(nn)
plot(nn)
plot(nn)
plot(nn)
plot(nn)
predicted_neural_values <- compute(nn,test_set[1:5])
predicted_neural_values <- compute(nn,test[1:5])
head(predicted_neural_values)
predicted_neural_values$net.result
table(test_set$Response, predicted_neural_values$net.result)
table(test$Response, predicted_neural_values$net.result)
predicted.neuralnetwork.values <- compute(nn,test_set[1:5])
predicted.neuralnetwork.values <- compute(nn,test[1:5])
idx <- apply(predicted.neuralnetwork.values$net.result , 1, which.max)
pred <- c("1","2","3","4","5","6","7","8")[idx]
table(test_set$Response,pred)
table(test$Response,pred)
table(test$Response,c("1","2","3","4","5","6","7","8")[idx])
